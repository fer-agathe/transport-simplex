[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Optimal Transport on Categorical Data for Counterfactuals using Compositional Data and Dirichlet Transport",
    "section": "",
    "text": "Introduction\nThis ebook provides replication codes for the article titled ‘Optimal Transport on Categorical Data for Counterfactuals using Compositional Data and Dirichlet Transport.’",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "Optimal Transport on Categorical Data for Counterfactuals using Compositional Data and Dirichlet Transport",
    "section": "Abstract",
    "text": "Abstract\nRecently, optimal transport-based approaches have gained attention for deriving counterfactuals, e.g., to quantify algorithmic discrimination. However, in the general multivariate setting, these methods are often opaque and difficult to interpret. To address this, alternative methodologies have been proposed, using causal graphs combined with iterative quantile regressions Plečko and Meinshausen (2020) or sequential transport Fernandes Machado, Charpentier, and Gallic (2025) to examine fairness at the individual level, often referred to as “counterfactual fairness.” Despite these advancements, transporting categorical variables remains a significant challenge in practical applications with real datasets. In this paper, we propose a novel approach to address this issue. Our method involves (1) converting categorical variables into compositional data and (2) transporting these compositions within the probabilistic simplex of \\(\\mathbb{R}^d\\). We demonstrate the applicability and effectiveness of this approach through an illustration on real-world data, and discuss limitations.\nKeywords: Fairness; Causality; Tractable probabilistic models; Simplex; Optimal Transport",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#outline",
    "href": "index.html#outline",
    "title": "Optimal Transport on Categorical Data for Counterfactuals using Compositional Data and Dirichlet Transport",
    "section": "Outline",
    "text": "Outline\nThis ebook contains three chapters:\n\nChapter 1  Toy dataset: Presentation of the methods, step by step, on a toy dataset.\nChapter 3  Adult Dataset: Illustration of estimation of counterfacutals on the German Credit dataset.\nChapter 2  German Credit Dataset: Illustration of estimation of counterfacutals on the adult dataset.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#r-package",
    "href": "index.html#r-package",
    "title": "Optimal Transport on Categorical Data for Counterfactuals using Compositional Data and Dirichlet Transport",
    "section": "R package",
    "text": "R package\nTo facilitate building on our approach, we put the main functions in an R package, available on GitHub.\nThe package needs to be installed:\n\nremotes::install_github(repo = \"fer-agathe/transport-simplex\")\nlibrary(transportsimplex)\n\nHere is a small example showing how to use the main functions: transport_simplex() (method 1) and wasserstein_simplex() and counterfactual_w() (method 2).\n\n# First three columns: probabilities of being of class A, B, or C.\n# Last column: group (0 or 1)\ndata(toydataset)\nX0 &lt;- toydataset[toydataset$group == 0, c(\"A\", \"B\", \"C\")]\nX1 &lt;- toydataset[toydataset$group == 1, c(\"A\", \"B\", \"C\")]\n\n# Method 1: \n# --------\n# Transport only, from group 0 to group 1, using centered log ratio transform:\ntransp &lt;- transport_simplex(X0 = X0, X1 = X1, isomorphism = \"clr\")\n\n# If we want to transport new points:\nnew_obs &lt;- data.frame(A = c(.2, .1), B = c(.6, .5), C = c(.2, .4))\n# transport_simplex_new(transport = transp, newdata = new_obs)\n\n# If we want to get interpolated values using McCann (1997) displacement\n# interpolation: (here, with 31 intermediate points)\ntransp_with_interp &lt;- transport_simplex(\n  X0 = X0, X1 = X1, isomorphism = \"clr\", n_interp = 31\n)\n# interpolated(transp_with_interp)[[1]] # first obs\n# interpolated(transp_with_interp)[[2]] # second obs\n\n# And displacement interpolation for the new obs:\ntransp_new_obs_with_interp &lt;- transport_simplex_new(\n  transport = transp, newdata = new_obs, n_interp = 5\n)\n# interpolated(transp_new_obs_with_interp)[[1]] # first new obs\n# interpolated(transp_new_obs_with_interp)[[1]] # second new obs\n\n# Method 2\n# --------\n# Optimal Transport using Linear Programming:\nmapping &lt;- wasserstein_simplex(as.matrix(X0), as.matrix(X1))\n# The counterfactuals of observations of group 0 in group 1\ncounterfactuals_0_1 &lt;- counterfactual_w(mapping, X0, X1)\n\n\n\nCode to create the Figure.\nlibrary(ggtern)\nlibrary(ggplot2)\n\n# Format path\ntransp_val_clr_inter_0_1 &lt;- \n  interpolated(transp_with_interp) |&gt; \n  purrr::list_rbind(names_to = \"id_obs\") |&gt; \n  dplyr::left_join(\n    toydataset |&gt; \n      dplyr::filter(group == 0) |&gt; \n      dplyr::mutate(id_obs = dplyr::row_number()) |&gt; \n      dplyr::select(id_obs, group),\n    by = \"id_obs\"\n  )\n\nggtern(\n  data = toydataset, \n  mapping = aes(x = A, y = C, z = B, colour = factor(group))\n) +\n  geom_point() +\n  geom_line(\n    data = transp_val_clr_inter_0_1, linewidth = .1,\n    mapping = aes(group = id_obs)\n  ) +\n  scale_colour_manual(values = c(\"0\" = \"red\", \"1\" = \"blue\"))\n\n\n\n\n\nFigure 1: Counterfactuals using the clr transformation and Gaussian optimal transports, \\(\\mu_{\\textcolor{red}{0}}\\mapsto\\mu_{\\textcolor{blue}{1}}\\).\n\n\n\n\n\n\n\n\n\n\n\n\nFernandes Machado, Agathe, Arthur Charpentier, and Ewen Gallic. 2025. “Sequential Conditional Transport on Probabilistic Graphs for Interpretable Counterfactual Fairness.” In Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 39.\n\n\nPlečko, Drago, and Nicolai Meinshausen. 2020. “Fair Data Adaptation with Quantile Preservation.” Journal of Machine Learning Research 21 (242): 1–44.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "application-toydataset.html",
    "href": "application-toydataset.html",
    "title": "1  Toy dataset",
    "section": "",
    "text": "1.1 Gaussian Mapping in the Euclidean Representation\nWe begin with loading a few packages:\nThen, we load the toy dataset:\nAssume that each of the three components A, B, and C are probabilities for an observation to be in class A, B, or C. Hence, for each observation, the sum of these three components always equals 1. Further assume that the observation come from two groups: group 0 or group 1.\nWe can use the ggtern() function from the {ggtern} package to display the observation in a ternary plot.\nThe average values in each group for the components:\nLet \\(\\mathbf{X}_0\\) and \\(\\mathbf{X}_1\\) be random vectors for observations in group 0 and group 1, respectively.\nAssume that both \\(\\mathbf{X}_0\\) and \\(\\mathbf{X}_1\\) take values in \\(\\mathcal{S}_d\\), and following an “normal distribution on the simplex.” Hence, for some isomorphism \\(h\\), the vectors of orthonormal coordinates, \\(\\mathbf{Z}_0=h(\\mathbf{X}_0)\\) and \\(\\mathbf{Z}_1=h(\\mathbf{X}_1)\\) both follow a multivariate normal distribution on \\(\\mathbb{R}^{d-1}\\).\nWe assume that \\(\\mathbf{Z}_0\\sim\\mathcal{N}(\\boldsymbol{\\mu}_0,\\boldsymbol{\\Sigma}_0)\\) and \\(\\mathbf{Z}_1\\sim\\mathcal{N}(\\boldsymbol{\\mu}_1,\\boldsymbol{\\Sigma}_1)\\). The optimal mapping writes: \\[\n\\mathbf{z}_{1} = T^\\star(\\mathbf{z}_{0})=\\boldsymbol{\\mu}_{1} + \\boldsymbol{A}(\\mathbf{z}_{0}-\\boldsymbol{\\mu}_{0}),    \n\\tag{1.1}\\]\nwhere \\(\\boldsymbol{A}\\) is a symmetric positive matrix that satisfies \\(\\boldsymbol{A}\\boldsymbol{\\Sigma}_{0}\\boldsymbol{A}=\\boldsymbol{\\Sigma}_{1}\\), which has a unique solution given by \\(\\boldsymbol{A}=\\boldsymbol{\\Sigma}_{0}^{-1/2}\\big(\\boldsymbol{\\Sigma}_{0}^{1/2}\\boldsymbol{\\Sigma}_{1}\\boldsymbol{\\Sigma}_{0}^{1/2}\\big)^{1/2}\\boldsymbol{\\Sigma}_{0}^{-1/2}\\), where \\(\\boldsymbol{M}^{1/2}\\) is the square root of the square (symmetric) positive matrix \\(\\boldsymbol{M}\\) based on the Schur decomposition (\\(\\boldsymbol{M}^{1/2}\\) is a positive symmetric matrix).\nLet us assume that \\(h=clr\\), i.e., the center log ratio (clr) transform, which is both an isomorphism and an isometry where \\({\\displaystyle \\operatorname {clr} :S^{d}\\rightarrow \\mathbb {R} ^{d}}\\), \\[\n     {\\displaystyle \\operatorname {clr} (\\mathbf{x})=\\left[\\log {\\frac {x_{1}}{\\overline{\\mathbf{x}}_g}},\\cdots ,\\log {\\frac {x_{D}}{\\overline{\\mathbf{x}}_g}}\\right]},\n\\tag{1.2}\\] where \\(\\overline{\\mathbf{x}}_g\\) denotes the geometric mean of \\(\\mathbf{x}\\).\nTo display the path from group 0 to group 1, we use McCann (1997) displacement interpolation. This allows us to have a continuous mapping \\(T_t^\\star\\) such that \\(T_1^\\star=T^\\star\\) and \\(T_0=Id\\), and so that \\(\\mathbf{Z}_{t}=T_t^\\star(\\mathbf{Z}_{0})\\) has distribution \\(\\mathcal{N}(\\boldsymbol{\\mu}_t,\\boldsymbol{\\Sigma}_t)\\) where \\(\\boldsymbol{\\mu}_t=(1-t)\\boldsymbol{\\mu}_0+t\\boldsymbol{\\mu}_1\\) and \\[\n\\boldsymbol{\\Sigma}_t = \\boldsymbol{\\Sigma}_0^{-1/2} \\left( (1 - t) \\boldsymbol{\\Sigma}_0 + t \\left( \\boldsymbol{\\Sigma}_0^{1/2} \\boldsymbol{\\Sigma}_1 \\boldsymbol{\\Sigma}_0^{1/2} \\right)^{1/2} \\right)^2 \\boldsymbol{\\Sigma}_0^{-1/2}.\n\\]\nWe use\nLet us give an example with R. First, we create subset of the data for group 0 and group 1:\nX0 &lt;- toydataset |&gt; filter(group == 0) |&gt; select(A, B, C)\nX1 &lt;- toydataset |&gt; filter(group == 1) |&gt; select(A, B, C)\nWe use the clr() function from the {compositions} package to compute the centered log ratio transform of each group:\nZ0 &lt;- matrix(clr(X0), ncol = 3)\nZ1 &lt;- matrix(clr(X1), ncol = 3)\nKeeping characteristics A and B only (from \\(S_d\\) to \\(\\mathbb{R}^{d-1}\\)), we obtain \\(h(\\mathbf{x}_{0,i})\\):\nZ0 &lt;- Z0[, 1:2]\nZ1 &lt;- Z1[, 1:2]\nWe compute \\(\\mathbf{m}_0\\) and \\(\\mathbf{m}_1\\), the averages of \\(\\{\\mathbf{z}_{0,1},\\cdots,\\mathbf{z}_{0,n_0}\\}\\) and \\(\\{\\mathbf{z}_{1,1},\\cdots,\\mathbf{z}_{1,n_1}\\}\\), respectively:\nm0 &lt;- apply(Z0, 2, mean)\nm1 &lt;- apply(Z1, 2, mean)\nWe compute \\(\\mathbf{S}_0\\) and \\(\\mathbf{S}_0\\), the empirical variance matrices of \\(\\{\\mathbf{z}_{0,1},\\cdots,\\mathbf{z}_{0,n_0}\\}\\) and \\(\\{\\mathbf{z}_{1,1},\\cdots,\\mathbf{z}_{1,n_1}\\}\\), respectively:\nS0 &lt;- var(Z0)\nS1 &lt;- var(Z1)\nThen, to apply optimal transport, we define the \\(A\\) matrix:\nA &lt;- solve(sqrtm(S0)) %*% \n  sqrtm(sqrtm(S0) %*% S1 %*% (sqrtm(S0))) %*% \n  solve(sqrtm(S0))\nLastly, we can compute the transported value: \\(\\displaystyle{h^{-1}\\big(\\mathbf{m}_{1} + \\boldsymbol{A}(h(\\mathbf{x}_{0})-\\mathbf{m}_{0})\\big)}\\)\nFor the first observation:\nX0[1,] # init\n\n# A tibble: 1 × 3\n      A     B     C\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.371 0.145 0.485\n\n(z &lt;- Z0[1,]) # clr\n\n[1]  0.2236776 -0.7156010\ntransp_z &lt;- as.numeric(m1 + A %*% (z - m0))\ntransp_z &lt;- clrInv(c(transp_z, -sum(transp_z)))\nNow, for the McCann’s displacement interpolation, assume we want to obtain 31 intermediate points:\nnb &lt;- 31\nvec_t &lt;- seq(0, 1, lengt = nb)\nvec_t\n\n [1] 0.00000000 0.03333333 0.06666667 0.10000000 0.13333333 0.16666667\n [7] 0.20000000 0.23333333 0.26666667 0.30000000 0.33333333 0.36666667\n[13] 0.40000000 0.43333333 0.46666667 0.50000000 0.53333333 0.56666667\n[19] 0.60000000 0.63333333 0.66666667 0.70000000 0.73333333 0.76666667\n[25] 0.80000000 0.83333333 0.86666667 0.90000000 0.93333333 0.96666667\n[31] 1.00000000\nWe initiate a matrix that will contain the interpolated values at each step:\ntransp_x &lt;- matrix(NA, nb, 3)\nAnd we simply apply the formula:\nfor(i in 1:nb) {\n  t &lt;- vec_t[i]\n  transp_z &lt;- (1 - t) * z + t * (m1 + A %*% (z - m0))\n  transp_z = as.numeric(transp_z)\n  transp_z = c(transp_z, -sum(transp_z))\n  transp_x[i,] = clrInv(transp_z)\n}\nhead(transp_x)\n\n          [,1]      [,2]      [,3]\n[1,] 0.3705655 0.1448577 0.4845768\n[2,] 0.3695008 0.1511263 0.4793729\n[3,] 0.3683175 0.1576141 0.4740684\n[4,] 0.3670129 0.1643244 0.4686628\n[5,] 0.3655842 0.1712601 0.4631557\n[6,] 0.3640289 0.1784237 0.4575473\nWe can wrap these in a small function. We actually define three functions to transport a single compositional observation from group 0 to group 1, each function considering a different transform:\n#' Gaussian-based transport of a single observation from group 0 to group 1\n#' on \\eqn{S_d}, using additive log ratio transform\n#'\n#' @param x Value to transport.\n#' @param n_interp Number of points for the interpolation.\n#' @param A Symmetric positive matrix from OT.\n#' @param m0 Average of transformed values in group 0.\n#' @param m1 Average of transformed values in group 1.\ntransport_x_alr &lt;- function(x,\n                            n_interp = 31,\n                            A,\n                            m0,\n                            m1) {\n\n  z &lt;- as.numeric(alr(as.numeric(x)))\n  vec_t &lt;- seq(0, 1, length = n_interp)\n  transp_x &lt;- matrix(NA, n_interp, length(x))\n  for(i in 1:n_interp) {\n    t &lt;- vec_t[i]\n    transp_z &lt;- (1 - t) * z + t * (m1 + A %*% (z - m0))\n    transp_z = as.numeric(transp_z)\n    transp_x[i,] = alrInv(transp_z)\n  }\n  transp_x\n}\n\n#' Gaussian-based transport of a single observation from group 0 to group 1\n#' on \\eqn{S_d}, using centered log ratio transform\n#'\n#' @param x Value to transport.\n#' @param n_interp Number of points for the interpolation.\n#' @param A Symmetric positive matrix from OT.\n#' @param m0 Average of transformed values in group 0.\n#' @param m1 Average of transformed values in group 1.\ntransport_x_clr &lt;- function(x,\n                            n_interp = 31,\n                            A,\n                            m0,\n                            m1) {\n\n  z &lt;- as.numeric(clr(as.numeric(x)))[1:(length(x)-1)]\n  vec_t &lt;- seq(0, 1, length = n_interp)\n  transp_x &lt;- matrix(NA, n_interp, length(x))\n  for(i in 1:n_interp) {\n    t &lt;- vec_t[i]\n    transp_z &lt;- (1 - t) * z + t * (m1 + A %*% (z - m0))\n    transp_z = as.numeric(transp_z)\n    transp_z = c(transp_z, -sum(transp_z))\n    transp_x[i,] = clrInv(transp_z)\n  }\n  transp_x\n}\n\n#' Gaussian-based transport of a single observation from group 0 to group 1\n#' on \\eqn{S_d}, using isometric log ratio transform\n#'\n#' @param x Value to transport.\n#' @param n_interp Number of points for the interpolation.\n#' @param A Symmetric positive matrix from OT.\n#' @param m0 Average of transformed values in group 0.\n#' @param m1 Average of transformed values in group 1.\ntransport_x_ilr &lt;- function(x,\n                            n_interp = 31,\n                            A,\n                            m0,\n                            m1) {\n\n  z &lt;- as.numeric(ilr(as.numeric(x)))\n  vec_t &lt;- seq(0, 1, length = n_interp)\n  transp_x &lt;- matrix(NA, n_interp, length(x))\n  for(i in 1:n_interp) {\n    t &lt;- vec_t[i]\n    transp_z &lt;- (1 - t) * z + t * (m1 + A %*% (z - m0))\n    transp_z = as.numeric(transp_z)\n    transp_x[i,] = ilrInv(transp_z)\n  }\n  transp_x\n}\nSince we estimated \\(\\mathbf{m}_0\\), \\(\\mathbf{m}_1\\), \\(\\mathbf{S}_0\\), \\(\\mathbf{S}_0\\), and therefore \\(A\\) after using the clr transform in our example, we use the transport_x_clr() function to transport an individual from group 0 to group 1. If we want to use another transform, we need to estimate new \\(\\mathbf{m}_0\\), \\(\\mathbf{m}_1\\), \\(\\mathbf{S}_0\\), \\(\\mathbf{S}_0\\) and \\(A\\).\ntransport_x_clr(x = X0[1,], n_interp = 5, A = A, m0 = m0, m1 = m1)\n\n          [,1]      [,2]      [,3]\n[1,] 0.3705655 0.1448577 0.4845768\n[2,] 0.3595718 0.1973433 0.4430849\n[3,] 0.3410945 0.2628282 0.3960772\n[4,] 0.3148558 0.3406194 0.3445249\n[5,] 0.2816910 0.4278495 0.2904595\nWe define two functions, get_ot_mapping() and transport_simplex(), to transport compositional data from group 0 to group 1, using a given transformation. The first one learns the mapping, and the second one applies it.\nThe get_ot_mapping() function.\n#' Learn OT mapping from group 0 to group 1 based on the representation of the\n#' composition data from the simplex (\\eqn{S_d}) to a \\eqn{d-1} Euclidean space.\n#'\n#' @param X0 Data frame with observations in group 0.\n#' @param X1 Data frame with observations in group 1.\n#' @param isomorphism Isomorphism used to map the composition data from the\n#'  simplex (\\eqn{S_d}) to a \\eqn{d-1} Euclidean space. Three possibilities: `\"alr\"`\n#'  (additive log ratio transform), `\"clr\"` (centered log ratio transform),\n#'  and `\"ilr\"` (isometric log ratio transform).\n#'\n#'  @returns A list with the following elements:\n#'  * `m0`, `m1`: empirical mean of \\eqn{z_0} and \\eqn{z_1} (vectors of orthonormal\n#'    coordinates).\n#'  * `S0`, `S1`: empirical covariance matrices of \\eqn{z_0} and \\eqn{z_1}.\n#'  * `A`: symmetric positive matrix that satisfies\n#'    \\eqn{\\bf{A}\\bf{\\Sigma}_{0}\\bf{A}=\\bf{\\Sigma}_{1}}\n#'  * `isomorphism`: name of the isomorphism used (alr, clr, irl).\n#'\n#' @importFrom compositions alr clr ilr alrInv clrInv ilrInv\n#' @importFrom stats var\n#' @importFrom expm sqrtm\nget_ot_mapping &lt;- function(X0,\n                           X1,\n                           isomorphism = c(\"clr\", \"alr\", \"ilr\")) {\n\n    isomorphism &lt;- match.arg(isomorphism)\n\n    if (isomorphism == \"alr\") {\n      Z0 &lt;- alr(X0)\n      Z1 &lt;- alr(X1)\n      transport_f_x &lt;- transport_x_alr\n    } else if (isomorphism == \"clr\") {\n      Z0 &lt;- matrix(clr(X0), ncol = ncol(X0))\n      Z1 &lt;- matrix(clr(X1), ncol = ncol(X1))\n      Z0 &lt;- Z0[, 1:(ncol(Z0)-1)]\n      Z1 &lt;- Z1[, 1:(ncol(Z1)-1)]\n      transport_f_x &lt;- transport_x_clr\n    } else {\n      Z0 &lt;- ilr(X0)\n      Z1 &lt;- ilr(X1)\n      transport_f_x &lt;- transport_x_ilr\n    }\n\n    # empirical mean in each group\n    m0 &lt;- apply(Z0, 2, mean)\n    m1 &lt;- apply(Z1, 2, mean)\n    # empirical variance in each group\n    S0 &lt;- var(Z0)\n    S1 &lt;- var(Z1)\n\n    A &lt;- solve(sqrtm(S0)) %*%\n      sqrtm(sqrtm(S0) %*% S1 %*% (sqrtm(S0))) %*%\n      solve(sqrtm(S0))\n\n    list(\n      m0 = m0,\n      m1 = m1,\n      S0 = S0,\n      S1 = S1,\n      A = A,\n      isomorphism = isomorphism\n    )\n\n}\nThe transport_simplex() function.\n#' Transport compositional data from group 0 to group 1\n#'\n#' @param X0 Data frame with observations in group 0.\n#' @param X1 Data frame with observations in group 1.\n#' @param isomorphism Isomorphism used to map the composition data from the\n#'  simplex (\\eqn{S_d}) to a \\eqn{d-1} Euclidean space. Three possibilities: `\"alr\"`\n#'  (additive log ratio transform), `\"clr\"` (centered log ratio transform),\n#'  and `\"ilr\"` (isometric log ratio transform).\n#' @param n_interp Number of steps in the interpolation (default to 1: no\n#'  interpolation).\n#'\n#' @returns A tibble with the transported values. If `n_interp` is larger than\n#'  1, the result also contains a list with the interpolated values, in the\n#'  `\"interpolated\"` attribute ; else, the attribute is `NULL`. The attribute\n#'  `\"ot_mapping\"` stores the mapping.\n#'\n#' @references  McCann, Robert J. 1997. \"A Convexity Principle for Interacting\n#' Gases.\" Advances in Mathematics 128 (1): 153–79.\n#'\n#' @importFrom rlang set_names\n#' @importFrom tibble as_tibble\n#' @importFrom purrr list_rbind map\n#' @importFrom dplyr slice_tail\ntransport_simplex &lt;- function(X0,\n                              X1,\n                              isomorphism = c(\"clr\", \"alr\", \"ilr\"),\n                              n_interp = 1) {\n  isomorphism &lt;- match.arg(isomorphism)\n  ot_mapping &lt;- get_ot_mapping(X0 = X0, X1 = X1, isomorphism = isomorphism)\n  # empirical mean in each group\n  m0 &lt;- ot_mapping$m0\n  m1 &lt;- ot_mapping$m1\n  # empirical variance in each group\n  S0 &lt;- ot_mapping$S0\n  S1 &lt;- ot_mapping$S1\n\n  A &lt;- ot_mapping$A\n\n  if (isomorphism == \"alr\") {\n    transport_f_x &lt;- transport_x_alr\n  } else if (isomorphism == \"clr\") {\n    transport_f_x &lt;- transport_x_clr\n  } else {\n    transport_f_x &lt;- transport_x_ilr\n  }\n\n  transported &lt;- map(\n    1:nrow(X0),\n    ~{\n      transp_val &lt;- transport_f_x(\n        x = X0[.x, ],  n_interp = n_interp, A = A, m0 = m0, m1 = m1\n      )\n      colnames(transp_val) &lt;- colnames(X0)\n      as_tibble(transp_val)\n    }\n  )\n\n  if (n_interp == 1) {\n    transported_val &lt;- transported |&gt; list_rbind()\n    interpolated &lt;- NULL\n  } else {\n    transported_val &lt;- map(transported, ~slice_tail(.x, n = 1)) |&gt; list_rbind()\n    interpolated &lt;- transported\n  }\n  structure(\n    transported_val,\n    interpolated = interpolated,\n    ot_mapping = ot_mapping\n  )\n}\n\n#' Extract the interpolated values of transported vectors of compositional data\n#' \n#' @param x Transported compositional data.\n#' @returns A list with the interpolated values. Each element contains a tibble\n#'  giving the interpolated values for an observation.\ninterpolated &lt;- function(x) {\n  attr(x, \"interpolated\")\n}\nFor the record, we also create a function (not used here) to transport a new observation. This function can be applied after a mapping has already been learned (it allows to avoid estimating again the mapping).\nThe transport_simplex_new() function.\n#' Transport new compositional data from group 0 to group 1 using a previously\n#' learned mapping.\n#'\n#' @param transport Previously learned mapping.\n#' @param newdata New data frame with composition data.\n#' @param n_interp Number of steps in the interpolation (default to 1: no\n#'  interpolation).\n#'\n#' @returns A tibble with the transported values. If `n_interp` is larger than\n#'  1, the result also contains a list with the interpolated values, in the\n#'  `\"interpolated\"` attribute ; else, the attribute is `NULL`. The attribute\n#'  `\"ot_mapping\"` stores the mapping.\n#'\n#' @references  McCann, Robert J. 1997. \"A Convexity Principle for Interacting\n#' Gases.\" Advances in Mathematics 128 (1): 153–79.\n#'\n#' @importFrom rlang set_names\n#' @importFrom tibble as_tibble\n#' @importFrom purrr list_rbind map\n#' @importFrom dplyr slice_tail\n#' @export\n#' @md\n#' @examples\n#' # First three columns: probabilities of being of class A, B, or C.\n#' # Last column: group (0 or 1)\n#' data(toydataset)\n#' X0 &lt;- toydataset[toydataset$group == 0, c(\"A\", \"B\", \"C\")]\n#' X1 &lt;- toydataset[toydataset$group == 1, c(\"A\", \"B\", \"C\")]\n#'\n#' # Transport only, from group 0 to group 1, using centered log ratio transform:\n#' transp &lt;- transport_simplex(X0 = X0, X1 = X1, isomorphism = \"clr\")\n#' head(transp)\n#'\n#' # If we want to transport new points:\n#' new_obs &lt;- data.frame(A = c(.2, .1), B = c(.6, .5), C = c(.2, .4))\n#' transp_new_obs &lt;- transport_simplex_new(transport = transp, newdata = new_obs)\n#' transp_new_obs\n#'\n#' # If we want to get interpolated values using McCann (1997) displacement\n#' # interpolation: (here, with 5 intermediate points)\n#' transp_new_obs_with_interp &lt;- transport_simplex_new(\n#'   transport = transp, newdata = new_obs, n_interp = 5\n#' )\n#' interpolated(transp_new_obs_with_interp)[[1]] # first new obs\n#' interpolated(transp_new_obs_with_interp)[[2]] # second new obs\ntransport_simplex_new &lt;- function(transport,\n                                  newdata,\n                                  n_interp = 1) {\n\n  ot_mapping &lt;- attr(transport, \"ot_mapping\")\n\n  # empirical mean in each group\n  m0 &lt;- ot_mapping$m0\n  m1 &lt;- ot_mapping$m1\n  # empirical variance in each group\n  S0 &lt;- ot_mapping$S0\n  S1 &lt;- ot_mapping$S1\n\n  A &lt;- ot_mapping$A\n\n  isomorphism &lt;- ot_mapping$isomorphism\n\n  if (isomorphism == \"alr\") {\n    transport_f_x &lt;- transport_x_alr\n  } else if (isomorphism == \"clr\") {\n    transport_f_x &lt;- transport_x_clr\n  } else {\n    transport_f_x &lt;- transport_x_ilr\n  }\n\n  transported &lt;- map(\n    1:nrow(newdata),\n    ~{\n      transp_val &lt;- transport_f_x(\n        x = newdata[.x, ],  n_interp = n_interp, A = A, m0 = m0, m1 = m1\n      )\n      colnames(transp_val) &lt;- colnames(newdata)\n      as_tibble(transp_val)\n    }\n  )\n\n  if (n_interp == 1) {\n    transported_val &lt;- transported |&gt; list_rbind()\n    interpolated &lt;- NULL\n  } else {\n    transported_val &lt;- map(transported, ~slice_tail(.x, n = 1)) |&gt; list_rbind()\n    interpolated &lt;- transported\n  }\n  structure(\n    transported_val,\n    interpolated = interpolated,\n    ot_mapping = ot_mapping\n  )\n}\nThe counterfactuals using the clr transformation and Gaussian optimal transports \\(\\mu_{\\textcolor{red}{0}}\\mapsto\\mu_{\\textcolor{blue}{1}}\\), is obtained as follows:\ntransp_val_clr_0_1 &lt;- transport_simplex(X0 = X0, X1 = X1, n_interp = 31)\nAnd the counterfactuals using the clr transformation and Gaussian optimal transports \\(\\mu_{\\textcolor{blue}{1}}\\mapsto\\mu_{\\textcolor{red}{0}}\\):\ntransp_val_clr_1_0 &lt;- transport_simplex(X0 = X1, X1 = X0, n_interp = 31)\nLet us plot the counterfactuals from group 0 to group 1 on a ternary plot, and show the displacement interpolation.\nLet us compute the average values of the three components of \\(\\mathbf{x}\\)’s and \\(T^\\star(\\mathbf{x})\\)’s.\nCodes to create the Table.\ntoydataset |&gt; \n  mutate(type = \"initial\") |&gt; \n  rename(init_group = group, init_colour = colour) |&gt; \n  bind_rows(\n    transp_val_clr_0_1 |&gt; \n      mutate(\n        init_group = factor(0, levels = c(0,1)), \n        init_colour = \"red\", type = \"Transported: clr_0_1\")\n  ) |&gt; \n  bind_rows(\n    transp_val_clr_1_0 |&gt; \n      mutate(\n        init_group = factor(1, levels = c(0,1)), \n        init_colour = \"blue\", type = \"Transported: clr_1_0\")\n  ) |&gt; \n  mutate(\n    type = factor(\n      type, levels = c(\"initial\", \"Transported: clr_0_1\", \n                       \"Transported: clr_1_0\")\n    )\n  ) |&gt; \n  group_by(type, init_group, init_colour) |&gt; \n  summarise(across(c(\"A\", \"B\", \"C\"), ~100*mean(.x))) |&gt; \n  arrange(type) |&gt; \n  kableExtra::kbl(booktabs = TRUE, digits = 3) |&gt; \n  kableExtra::kable_paper()\n\n\n\n\nTable 1.2: Average value for each category in both groups, before and after transport (in %).\n\n\n\n\n\n\ntype\ninit_group\ninit_colour\nA\nB\nC\n\n\n\n\ninitial\n0\nred\n43.713\n18.572\n37.715\n\n\ninitial\n1\nblue\n29.831\n48.605\n21.564\n\n\nTransported: clr_0_1\n0\nred\n29.670\n48.826\n21.504\n\n\nTransported: clr_1_0\n1\nblue\n43.728\n18.553\n37.719\nThe transformed points \\(\\mathbf{z}=h(\\mathbf{x})\\) are supposed to be normally distributed. Recall that we used multivariate optimal transport. Hence, \\(T_t^\\star\\) is linear in \\(\\mathbb{R}^{d-1}\\), as given by expression Equation 1.1, as well as displacement interpolation, corresponding to red and blue segments in Figure 1.5. Note that in fig-ternary-clr-toydataset, in the original space, \\(t\\mapsto \\mathbf{x}_{t}:=h^{-1}(\\mathbf{z}_{t})\\) is nonlinear.\nCodes to create the Figure.\ntransported_z_0 &lt;- \n  apply(Z0, MARGIN = 1, function(z) as.numeric(m1 + A %*% (z - m0))) |&gt; \n  t() |&gt; \n  as_tibble()\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\nCodes to create the Figure.\ncolnames(transported_z_0) &lt;- c(\"V1_t\", \"V2_t\")\n\ntransported_z_1 &lt;- \n  apply(Z1, MARGIN = 1, function(z) as.numeric(m0 + A %*% (z - m1))) |&gt; \n  t() |&gt; \n  as_tibble()\ncolnames(transported_z_1) &lt;- c(\"V1_t\", \"V2_t\")\n\nmap_both &lt;- bind_cols(transported_z_0, as_tibble(Z0)) |&gt; \n  mutate(\n    group = factor(0, levels = c(0, 1)),\n    type = \"group 0 to 1\"\n  ) |&gt; \n  bind_rows(\n    bind_cols(transported_z_1, as_tibble(Z1)) |&gt; \n      mutate(\n        group = factor(1, levels = c(0, 1)),\n        type = \"group 1 to 0\")\n  )\n\n\nggplot(\n  data = as_tibble(Z0) |&gt; mutate(group = 0) |&gt; \n    bind_rows(\n      as_tibble(Z1) |&gt; mutate(group = 1)\n    ) |&gt; \n    mutate(group = factor(group)),\n  mapping = aes(x = V1, y = V2, colour = group)\n) +\n  geom_point() +\n  geom_segment(\n    data = map_both,\n    mapping = aes(xend = V1_t, yend = V2_t)\n  ) +\n  scale_colour_manual(values = col_groups) +\n  coord_equal(xlim = c(-1.3, 1.3)) +\n  labs(x = NULL, y = NULL) +\n  facet_wrap(~type) +\n  stat_ellipse()\n\n\n\n\n\nFigure 1.5: Optimal transport in \\(\\mathbb{R}^2\\), on \\(\\mathbf{z}_{\\textcolor{red}{0},i}\\)’s and \\(\\mathbf{z}_{\\textcolor{blue}{1},i}\\)’s.\nggtern(\n  data = toydataset, \n  mapping = aes(x = A, y = C, z = B, colour = group)\n    ) +\n  geom_point() +\n  scale_colour_manual(values = col_groups) +\n  stat_density_tern(\n    geom = \"polygon\",\n    fill = NA\n  ) +\n  facet_wrap(~group)\n\n\n\n\nFigure 1.6: \\(n=61\\) points in \\(\\mathcal{S}_3\\), with a toy dataset.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Toy dataset</span>"
    ]
  },
  {
    "objectID": "application-toydataset.html#sec-first-method",
    "href": "application-toydataset.html#sec-first-method",
    "title": "1  Toy dataset",
    "section": "",
    "text": "Note\n\n\n\nWe want to transport values from group 0 to group group 1.\n\n\n\n\n\n\n\n\n\n\n\\begin{algorithm} \\caption{Gaussian Based Transport of $\\mathbf{x}_0$ on $\\mathcal{S}_d$} \\begin{algorithmic} \\STATE \\textbf{Input:} $\\mathbf{x}_0$ ($\\in\\mathcal{S}_d$)\\\\ \\STATE \\textbf{Parameter:} $\\{\\mathbf{x}_{0,1},\\cdots,\\mathbf{x}_{0,n_0}\\}$ and $\\{\\mathbf{x}_{1,1},\\cdots,\\mathbf{x}_{1,n_1}\\}$ in $\\mathcal{S}_d$;\\\\ \\STATE $\\quad$ isomorphic transformation $h:\\mathcal{S}_d\\to\\mathbb{R}^{d-1}$\\\\ \\STATE \\textbf{Output}: $\\mathbf{x}_{1}$\\\\ \\For{$i\\in\\{1,\\cdots,n_0\\}$} \\STATE $\\mathbf{z}_{0,i}\\gets h(\\mathbf{x}_{0,i})$ \\EndFor \\For{$i\\in\\{1,\\cdots,n_1\\}$} \\STATE $\\mathbf{z}_{1,i}\\gets h(\\mathbf{x}_{1,i})$ \\EndFor \\STATE $\\mathbf{m}_0\\gets$ average of $\\{\\mathbf{z}_{0,1},\\cdots,\\mathbf{z}_{0,n_0}\\}$\\\\ \\STATE $\\mathbf{m}_1\\gets$ average of $\\{\\mathbf{z}_{1,1},\\cdots,\\mathbf{z}_{1,n_1}\\}$\\\\ \\STATE $\\mathbf{S}_0\\gets$ empirical variance matrix of $\\{\\mathbf{z}_{0,1},\\cdots,\\mathbf{z}_{0,n_0}\\}$\\\\ \\STATE $\\mathbf{S}_1\\gets$ empirical variance matrix of $\\{\\mathbf{z}_{1,1},\\cdots,\\mathbf{z}_{1,n_1}\\}$\\\\ \\STATE $\\boldsymbol{A}\\gets \\boldsymbol{S}_{0}^{-1/2}\\big(\\boldsymbol{S}_{0}^{1/2}\\boldsymbol{S}_{1}\\boldsymbol{S}_{0}^{1/2}\\big)^{1/2}\\boldsymbol{S}_{0}^{-1/2}$\\\\ \\STATE $\\mathbf{x}_{1} \\gets \\displaystyle{h^{-1}\\big(\\mathbf{m}_{1} + \\boldsymbol{A}(h(\\mathbf{x}_{0})-\\mathbf{m}_{0})\\big)}$\\\\ \\end{algorithmic} \\end{algorithm}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntransport_x_alr(): additive log ratio transform.\ntransport_x_clr(): centered log ratio transform.\ntransport_x_ilr(): isometric log ratio transform.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCentered log transformAdditive log transformIsometric log transform\n\n\n\n\nCode to create the Figure.\n# Add group\ntransp_val_clr_inter_0_1 &lt;- \n  interpolated(transp_val_clr_0_1) |&gt; list_rbind(names_to = \"id_obs\") |&gt; \n  left_join(\n    toydataset |&gt; filter(group == 0) |&gt; mutate(id_obs = row_number()) |&gt; \n      select(id_obs, group, colour),\n    by = \"id_obs\"\n  )\n\ntransp_val_clr_inter_1_0 &lt;- \n  interpolated(transp_val_clr_1_0) |&gt; list_rbind(names_to = \"id_obs\") |&gt; \n  left_join(\n    toydataset |&gt; filter(group == 1) |&gt; mutate(id_obs = row_number()) |&gt; \n      select(id_obs, group, colour),\n    by = \"id_obs\"\n  )\n\ntransp_val_clr_inter_both &lt;- \n  transp_val_clr_inter_0_1 |&gt; mutate(type = \"from 0 to 1\") |&gt; \n  bind_rows(\n    transp_val_clr_inter_1_0 |&gt; mutate(type = \"from 1 to 0\")\n  )\n\nggtern(\n  data = toydataset, \n  mapping = aes(x = A, y = C, z = B, colour = group)\n) +\n  geom_point() +\n  geom_line(\n    data = transp_val_clr_inter_both, linewidth = .1,\n    mapping = aes(group = id_obs)\n  ) +\n  scale_colour_manual(values = col_groups) +\n  facet_wrap(~type)\n\n\n\n\n\nFigure 1.2: Counterfactuals using the clr transformation and Gaussian optimal transports, \\(\\mu_{\\textcolor{red}{0}}\\mapsto\\mu_{\\textcolor{blue}{1}}\\) (left), and \\(\\mu_{\\textcolor{blue}{1}}\\mapsto\\mu_{\\textcolor{red}{0}}\\) (right).\n\n\n\n\n\n\n\n\n\n\n\n\nCode to create the Figure.\ntransp_val_alr_0_1 &lt;- transport_simplex(X0 = X0, X1 = X1, n_interp = 31, isomorphism = \"alr\")\ntransp_val_alr_1_0 &lt;- transport_simplex(X0 = X1, X1 = X0, n_interp = 31, isomorphism = \"alr\")\n\n# Add group\ntransp_val_alr_inter_0_1 &lt;- \n  interpolated(transp_val_alr_0_1) |&gt; list_rbind(names_to = \"id_obs\") |&gt; \n  left_join(\n    toydataset |&gt; filter(group == 0) |&gt; mutate(id_obs = row_number()) |&gt; \n      select(id_obs, group, colour),\n    by = \"id_obs\"\n  )\n\ntransp_val_alr_inter_1_0 &lt;- \n  interpolated(transp_val_alr_1_0) |&gt; list_rbind(names_to = \"id_obs\") |&gt; \n  left_join(\n    toydataset |&gt; filter(group == 1) |&gt; mutate(id_obs = row_number()) |&gt; \n      select(id_obs, group, colour),\n    by = \"id_obs\"\n  )\n\ntransp_val_alr_inter_both &lt;- \n  transp_val_alr_inter_0_1 |&gt; mutate(type = \"from 0 to 1\") |&gt; \n  bind_rows(\n    transp_val_alr_inter_1_0 |&gt; mutate(type = \"from 1 to 0\")\n  )\n\nggtern(\n  data = toydataset, \n  mapping = aes(x = A, y = C, z = B, colour = group)\n) +\n  geom_point() +\n  geom_line(\n    data = transp_val_alr_inter_both, linewidth = .1,\n    mapping = aes(group = id_obs)\n  ) +\n  scale_colour_manual(values = col_groups) +\n  facet_wrap(~type)\n\n\n\n\n\nFigure 1.3: Counterfactuals using the alr transformation and Gaussian optimal transports, \\(\\mu_{\\textcolor{red}{0}}\\mapsto\\mu_{\\textcolor{blue}{1}}\\) (left), and \\(\\mu_{\\textcolor{blue}{1}}\\mapsto\\mu_{\\textcolor{red}{0}}\\) (right).\n\n\n\n\n\n\n\n\n\n\n\n\nCode to create the Figure.\ntransp_val_ilr_0_1 &lt;- transport_simplex(X0 = X0, X1 = X1, n_interp = 31, isomorphism = \"ilr\")\ntransp_val_ilr_0_1 &lt;- transport_simplex(X0 = X1, X1 = X0, n_interp = 31, isomorphism = \"ilr\")\n\n# Add group\ntransp_val_ilr_inter_0_1 &lt;- \n  interpolated(transp_val_ilr_0_1) |&gt; list_rbind(names_to = \"id_obs\") |&gt; \n  left_join(\n    toydataset |&gt; filter(group == 0) |&gt; mutate(id_obs = row_number()) |&gt; \n      select(id_obs, group, colour),\n    by = \"id_obs\"\n  )\n\ntransp_val_ilr_inter_1_0 &lt;- \n  interpolated(transp_val_ilr_0_1) |&gt; list_rbind(names_to = \"id_obs\") |&gt; \n  left_join(\n    toydataset |&gt; filter(group == 1) |&gt; mutate(id_obs = row_number()) |&gt; \n      select(id_obs, group, colour),\n    by = \"id_obs\"\n  )\n\ntransp_val_ilr_inter_both &lt;- \n  transp_val_ilr_inter_0_1 |&gt; mutate(type = \"from 0 to 1\") |&gt; \n  bind_rows(\n    transp_val_ilr_inter_1_0 |&gt; mutate(type = \"from 1 to 0\")\n  )\n\nggtern(\n  data = toydataset, \n  mapping = aes(x = A, y = C, z = B, colour = group)\n) +\n  geom_point() +\n  geom_line(\n    data = transp_val_ilr_inter_both, linewidth = .1,\n    mapping = aes(group = id_obs)\n  ) +\n  scale_colour_manual(values = col_groups) +\n  facet_wrap(~type)\n\n\n\n\n\nFigure 1.4: Counterfactuals using the ilr transformation and Gaussian optimal transports, \\(\\mu_{\\textcolor{red}{0}}\\mapsto\\mu_{\\textcolor{blue}{1}}\\) (left), and \\(\\mu_{\\textcolor{blue}{1}}\\mapsto\\mu_{\\textcolor{red}{0}}\\) (right).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Toy dataset</span>"
    ]
  },
  {
    "objectID": "application-toydataset.html#sec-second-method",
    "href": "application-toydataset.html#sec-second-method",
    "title": "1  Toy dataset",
    "section": "1.2 Optimal Transport for Measures on \\(\\mathcal{S}_d\\)",
    "text": "1.2 Optimal Transport for Measures on \\(\\mathcal{S}_d\\)\nA function \\(\\psi:\\mathcal{S}_d\\to\\mathbb{R}\\) is exponentially concave if \\(\\exp[\\psi]:\\mathcal{S}_d\\to\\mathbb{R}_+\\) is concave. As a consequence, such a function \\(\\psi\\) is differentiable almost everywhere. Let \\(\\nabla \\psi\\) and \\(\\nabla_{\\overrightarrow{u}} \\psi\\) denote, respectively, its gradient, and its directional derivative. Following Pal and Wong (2020), define an allocation map generated by \\(\\psi\\), \\(\\pi_\\psi:\\mathcal{S}_d\\to\\mathcal{S}_d\\) defined as \\[\n\\pi_\\psi(\\mathbf{x})=\\left[\nx_1\\big(1+\\nabla_{\\overrightarrow{e}_1-\\mathbf{x}} \\psi(\\mathbf{x}) \\big),\n\\cdots,\nx_d\\big(1+\\nabla_{\\overrightarrow{e}_d-\\mathbf{x}} \\psi(\\mathbf{x}) \\big)\n\\right],\n\\tag{1.3}\\] where \\(\\left\\{\\overrightarrow{e}_1,\\cdots,\\overrightarrow{e}_{d}\\right\\}\\) is the standard orthonormal basis of \\(\\mathbb{R} ^{d}\\).\nConsider the Monge-Kantorovitch optimal transport problem on the unit simplex, with the following cost function (Pal and Wong 2020):\n\\[\nc(\\mathbf{x},\\mathbf{y})=\\log\\left(\\frac{1}{d}\\sum_{i=1}^d\\frac{y_i}{x_i}\\right)-\\frac{1}{d}\\sum_{i=1}^d\\log\\left(\\frac{y_i}{x_i}\\right), \\quad \\mathbf{x},\\mathbf{y} \\in \\mathcal{S}_d.\n\\tag{1.4}\\]\nFrom Theorem 1 in Pal and Wong (2020), for this cost function, there exists an exponentially concave function \\(\\psi^\\star:\\mathcal{S}_d\\to\\mathbb{R}\\) such that \\[\nT^\\star(\\mathbf{x}) = \\mathbf{x}\\diamond \\pi_{\\psi^\\star}\\big(\\mathbf{x}^{-1}\\big)\n\\tag{1.5}\\] defines a push-forward from \\(\\mathbb{P}_0\\) to \\(\\mathbb{P}_1\\), and the coupling \\((\\mathbf{x},T^\\star(\\mathbf{x}))\\) is optimal for Monge problem, and is unique if \\(\\mathbb{P}_0\\) is absolutely continuous.\nWith these theoretical properties recalled, we can turn to matching. Consider two samples in the \\(\\mathcal{S}_d\\) simplex, \\(\\{\\mathbf{x}_{0,1},\\cdots,\\mathbf{x}_{0,n_0}\\}\\) and \\(\\{\\mathbf{x}_{1,1},\\cdots,\\mathbf{x}_{1,n_1}\\}\\). The discrete version of the Kantorovich problem is \\[\n\\underset{\\mathrm{P}\\in   U(n_{0},n_{1})}{\\min} \\left\\lbrace \\sum_{i=1}^{{n_{0}}} \\sum_{j=1}^{{n_{1}}} \\mathrm{P}_{i,j}\\mathrm{C}_{i,j} \\right\\rbrace\n\\tag{1.6}\\]\nwhere, as in Brualdi (2006), \\(U(n_{0},n_{1})\\) is the set of \\({n_{0}}\\times {n_{1}}\\) matrices corresponding to the convex transportation polytope \\[\nU(n_{0},n_{1})=\\left\\lbrace\n\\mathrm{P}:\\mathrm{P}\\boldsymbol{1}_{{n_{1}}}=\\boldsymbol{1}_{n_{0}}\\text{ and }{\\mathrm{P}}^\\top\\boldsymbol{1}_{{n_{0}}}=\\frac{n_0}{n_1}\\boldsymbol{1}_{n_{1}}\n\\right\\rbrace,\n\\tag{1.7}\\] and where \\(\\mathrm{C}\\) denotes the \\({n_{0}}\\times {n_{1}}\\) cost matrix, \\(\\mathrm{C}_{i,j}=c(\\mathbf{x}_i,\\mathbf{x}_{j})\\), associated with cost from Equation (Equation 1.4).\nLet us use the procedure explained in Peyré, Cuturi, et al. (2019) (with a specific cost function, from Equation 1.4) to couple samples on \\(\\mathcal{S}_d\\), summarized in Algorithm 1.2.\n\n\n\\begin{algorithm} \\caption{Coupling samples on $\\mathcal{S}_d$} \\begin{algorithmic} \\STATE \\textbf{Input:} $\\{\\mathbf{x}_{0,1},\\cdots,\\mathbf{x}_{0,n_0}\\}$ and $\\{\\mathbf{x}_{1,1},\\cdots,\\mathbf{x}_{1,n_1}\\}$ in $\\mathcal{S}_d$;\\\\ \\STATE \\textbf{Input:} weight matching matrix $n_0\\times n_1$ $\\mathbf{P}^*$\\\\ \\STATE $\\mathbf{C} \\gets $ matrix $n_0\\times n_1$, $\\mathbf{C}_{i,j}=c(\\mathbf{x}_i,\\mathbf{x}_j)$\\\\ \\STATE $\\mathbf{P}^\\star \\gets$ solution the discrete Kantorovich problem, using LP libraries \\end{algorithmic} \\end{algorithm}\n\n\nFirst, we define the cost function:\n\n#' Cost function for optimal transport on the unit simplex\nd_s &lt;- function(x, y) {\n  d &lt;- length(x)\n  log(mean(y / x)) - mean(log(y / x))\n}\n\nThen, we need to define a few helper functions to solve the optimal transport problem.\n\n\nA few helper functions.\n#' Pairwise distance matrix on the simplex\n#'\n#' @description\n#' Computes the pairwise distance matrix of observations in the simplex, using\n#' the cost function for optimal transport on the unit simplex as the distance\n#' metric.\n#'\n#' @param X Matrice of observations (one observation per row).\n#' @param Y Matrice of observations (one observation per row).\n#'\n#' @returns A matrix of size m x n, where m is the number of observation in X,\n#'  and n is the number of observations in X, containing the distances between\n#'  observations in X and Y.\n#' @noRd\ncompute_pdist_simplex &lt;- function(X, Y) {\n  M &lt;- matrix(NA, nrow(X), nrow(Y))\n  for (i in 1:nrow(X)) {\n    for (j in 1:nrow(Y)) {\n      M[i, j] &lt;- d_s(X[i, ], Y[j, ])\n    }\n  }\n  M\n}\n\n#' Ensures that a weight vector (marginal distribution) is valid\n#'\n#' @description\n#' Returns a uniform weight if the provided vector if NULL. Otherwise, checks\n#' if the vector has length M and nonnegative entries, and if so, normalizes\n#' the vector of weights to sum to 1.\n#'\n#' @param mvec (Optional) Vector of weights.\n#' @param M Length of the weight vector.\n#' @param fname Name of the distance used (string).\n#' @noRd\nvalid_single_marginal &lt;- function(mvec, M, fname) {\n  dname &lt;- paste0(\"'\", deparse(substitute(mvec)), \"'\")\n  if ((length(mvec) == 0) && is.null(mvec)) {\n    return(rep(1 / M, M))\n  } else {\n    mvec &lt;- as.vector(mvec)\n    if ((length(mvec) != M) || (any(mvec &lt; 0))) {\n      stop(\n        paste0(\n          \"* \", fname, \" : \", dname,\n          \" should be a nonnegative vector of length \",M,\".\"\n        )\n      )\n    }\n    return(mvec / base::sum(mvec))\n  }\n}\n\n#' Solving the Optimal Transport Problem\n#'\n#' @description\n#' Finds the optimal transport plan using linear programming.\n#' In a first attempts, it uses `CVXR::solve` with the OSQP solver.\n#' If this fails, it uses `lpSolve::lp` instead.\n#' The function minimizes the transport cost while ensuring:\n#' * Mass conservation (row and column sums match the marginals).\n#' * Nonnegative transport flows.\n#'\n#' @param dxy Cost matrix of transport distances between points in X and Y.\n#' @param wx Weights (marginal distribution) for X.\n#' @param wy Weights (marginal distribution) for Y.\n#' @param p Order of the Wassterstein distance. (If p=2: squared Euclidean\n#'  cost).\n#'\n#' @importFrom CVXR Variable Minimize matrix_trace Problem solve\n#' @importFrom lpSolve lp\n#'\n#' @noRd\nwass_lp &lt;- function(dxy,\n                    wx,\n                    wy,\n                    p) {\n  cxy    &lt;- (dxy)\n  m      &lt;- length(wx)\n  ww_m   &lt;- matrix(wx, ncol = 1)\n  n      &lt;- length(wy)\n  ww_n   &lt;- matrix(wy, nrow = 1)\n  ones_m &lt;- matrix(rep(1, n), ncol = 1)\n  ones_n &lt;- matrix(rep(1, m), nrow = 1)\n  plan   &lt;- CVXR::Variable(m, n)\n\n  wd.obj    &lt;- CVXR::Minimize(CVXR::matrix_trace(t(cxy) %*% plan))\n  wd.const1 &lt;- list(plan &gt;= 0)\n  wd.const2 &lt;- list(plan %*% ones_m == ww_m, ones_n %*% plan == ww_n)\n  wd.prob   &lt;- CVXR::Problem(wd.obj, c(wd.const1, wd.const2))\n  wd.solve  &lt;- CVXR::solve(wd.prob, solver = \"OSQP\")\n\n  if (all(wd.solve$status==\"optimal\")) {\n    # successful\n    gamma &lt;- wd.solve$getValue(plan)\n    value &lt;- (base::sum(gamma * cxy))\n  } else {\n    # failed : use lpsolve\n    cxy &lt;- (dxy)\n    m   &lt;- nrow(cxy)\n    n   &lt;- ncol(cxy)\n\n    c  &lt;- as.vector(cxy)\n    A1 &lt;- base::kronecker(matrix(1, nrow = 1, ncol = n), diag(m))\n    A2 &lt;- base::kronecker(diag(n), matrix(1, nrow = 1, ncol = m))\n    A  &lt;- rbind(A1, A2)\n\n    f.obj &lt;- c\n    f.con &lt;- A\n    f.dir &lt;- rep(\"==\", nrow(A))\n    f.rhs &lt;- c(rep(1 / m, m), rep(1 / n, n))\n    f.sol &lt;- (lpSolve::lp(\"min\", f.obj, f.con, f.dir, f.rhs))\n\n    gamma &lt;- matrix(f.sol$solution, nrow = m)\n    value &lt;- (sum(gamma*cxy)^(1 / p))\n  }\n  list(distance = value, plan = gamma)\n}\n\n\nThe main function is the following, wasserstein_simplex():\n\n#' Wasserstein distance between two sets of probability vectors X and Y\n#'\n#' @param X Matrix of probability vectors in a first group.\n#' @param Y Matrix of probability vectors in a second group.\n#' @param wx Weights (marginal distribution) for X. Default to `NULL` (uniform\n#' weights will be used).\n#' @param wy Weights (marginal distribution) for Y. Default to `NULL` (uniform\n#' weights will be used).\n#'\n#' @returns A list with two elements:\n#' * `distance`: the Wassterstein distance\n#' * `plan`: the optimal transport plan describing how mass is transported\n#'   between X and Y.\n#' @export\nwasserstein_simplex &lt;- function(X,\n                                Y,\n                                wx = NULL,\n                                wy = NULL) {\n  ## CHECK INPUTS\n  if (is.vector(X)) {\n    X &lt;- matrix(X, ncol = 1)\n  }\n  if (is.vector(Y)) {\n    Y &lt;- matrix(Y, ncol = 1)\n  }\n  if (!is.matrix(X)) { stop(\"* wasserstein : input 'X' should be a matrix.\") }\n  if (!is.matrix(Y)) { stop(\"* wasserstein : input 'Y' should be a matrix.\") }\n  if (base::ncol(X) != base::ncol(Y)){\n    stop(\"* wasserstein : input 'X' and 'Y' should be of same dimension.\")\n  }\n\n  # Number of observation in each matrix\n  m &lt;- base::nrow(X)\n  n &lt;- base::nrow(Y)\n\n  wxname &lt;-  paste0(\"'\",deparse(substitute(wx)),\"'\")\n  wyname &lt;- paste0(\"'\",deparse(substitute(wy)),\"'\")\n  fname  &lt;- \"wasserstein\"\n\n  # Weight normalization\n  par_wx &lt;- valid_single_marginal(wx, m, fname)\n  par_wy &lt;- valid_single_marginal(wy, n, fname)\n\n  # Cost matrix\n  dist_mat  &lt;- compute_pdist_simplex(X, Y)\n\n  # Solve the optimal transport problem\n  wass_lp(dist_mat, par_wx, par_wy, p = 2)\n}\n\nLet us transform the tibble that contains the vectors of probabilities in each group in two matrices:\n\ntP0 &lt;- as.matrix(X0)\ntP1 &lt;- as.matrix(X1)\n\nThere are \\(m_0=38\\) observations in group 0 and \\(n_1=23\\) in group 1:\n\nrbind(dim(tP0), dim(tP1))\n\n     [,1] [,2]\n[1,]   38    3\n[2,]   23    3\n\n\nThe Wasserstein distance and transport plan from group 0 to group 1 is obtained as follows:\n\nW_xy &lt;- wasserstein_simplex(tP0, tP1)\n\nThe obtained transport plan is an \\(n_0 \\times n_1\\) matrix:\n\ndim(W_xy$plan)\n\n[1] 38 23\n\n\nWe can check if row sums match the uniform weights used (we did not provide weights in the wasserstein_simplex() function, so uniform weights were used).\n\napply(W_xy$plan, 1, sum)\n\n [1] 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n [7] 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n[13] 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n[19] 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n[25] 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n[31] 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n[37] 0.02631579 0.02631579\n\n1/nrow(tP0)\n\n[1] 0.02631579\n\n\nAnd the column sums:\n\napply(W_xy$plan, 2, sum)\n\n [1] 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n [7] 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n[13] 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n[19] 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n\n1/nrow(tP1)\n\n[1] 0.04347826\n\n\nScaling the transport plan to the original number of observations:\n\nM0 &lt;- W_xy$plan * nrow(X0)\n\nLet us isolate the first observation in group 0. Since \\(n_0\\neq n_1\\), the “counterfactual” of \\(\\mathbf{x}_{0,i}\\) is not obtained with a coupling: it is a weighted average of \\(\\mathbf{x}_{1,j}\\), where weights are given in row \\(\\mathbf{P}^\\star_i=[\\mathbf{P}^\\star_{i,1},\\cdots,\\mathbf{P}^\\star_{i,n_1}]\\in\\mathcal{S}_{n_1}\\).\nThe weights \\(\\mathbf{P}^\\star_1\\):\n\ni &lt;- 1\nM0[i, ]\n\n [1] -2.770445e-21  2.638607e-21  9.398934e-22 -5.803349e-21  4.220959e-21\n [6]  9.831785e-22 -2.242821e-21 -1.121761e-21  4.748530e-21 -9.240347e-22\n[11]  1.715187e-21 -2.861133e-21 -2.902400e-21  1.979053e-21 -3.990408e-21\n[16] -4.748569e-21  1.000000e+00 -1.385394e-21 -3.430030e-21  4.748637e-21\n[21]  1.780860e-21 -7.922109e-22 -7.256618e-22\n\n\nWe can notice that the 17 observation has a larger weight:\n\nwhich(M0[i, ]&gt;.1)\n\n[1] 17\n\n\nWe can then compute the counterfactual of the first observation from group 0, \\(\\mathbf{x}_{\\textcolor{red}{0},i}\\):\n\nweights_i &lt;- M0[i,]\ncounterfactual_i &lt;- weights_i %*% tP1\ncounterfactual_i\n\n             A         B         C\n[1,] 0.3167699 0.4324855 0.2507445\n\n\nFor the reccord, the Gaussian optimal transport was:\n\ngaussian_t_obs_i &lt;- transp_val_clr_0_1[i, ]\ngaussian_t_obs_i\n\n# A tibble: 1 × 3\n      A     B     C\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.282 0.428 0.290\n\n\nAnd let us extract the interpolated path to display in on a graph.\n\ngaussian_t_obs_i_interp &lt;- interpolated(transp_val_clr_0_1)[[i]]\n\nWe can visualize on a ternary plot the point of interest \\(\\mathbf{x}_{\\textcolor{red}{0},i}\\), its counterfactual \\(T^\\star(\\mathbf{x}_{\\textcolor{red}{0},i})\\) (big blue square). The size of the blue dots matches the weights.\n\n\nCodes to create the Figure.\np_1 &lt;- ggtern(\n  data = toydataset |&gt; filter(group == 0), \n  mapping = aes(x = A, y = C, z = B, colour = group)\n) +\n  geom_point(size = .2) +\n  # Focus on the first obs in group 0\n  geom_point(\n    data = toydataset |&gt; filter(group == 0) |&gt; slice(!!i),\n    size = 3\n  ) +\n  # Display observations in group 1 where size is function of the\n  # obtained weight\n  geom_point(\n    data = toydataset |&gt; filter(group == 1) |&gt;\n      mutate(weight = M0[i,]),\n    mapping = aes(size = weight),\n    alpha = .5\n  ) +\n  # Display the counterfactual\n  geom_point(\n    data = gaussian_t_obs_i |&gt; \n      mutate(\n        group = factor(1, levels = c(0, 1)), \n        colour = factor(col_groups[[\"1\"]], levels = levels(toydataset$colour))\n      ),\n    size = 2,\n    shape = 15\n  ) +\n  # Display the interpolation path obtained with Gaussian OT\n  geom_line(\n    data = gaussian_t_obs_i_interp |&gt; \n      mutate(\n        group = factor(0, levels = c(0, 1)), \n        colour = factor(col_groups[[\"0\"]], levels = levels(toydataset$colour))\n      ),\n    linewidth = 1\n  ) +\n  # geom_point(\n  #   data = gaussian_t_obs_i |&gt; \n  #     mutate(\n  #       group = factor(1, levels = c(0, 1)), \n  #       colour = factor(col_groups[[\"1\"]], levels = levels(toydataset$colour))\n  #     ),\n  #   size = 2,\n  #   shape = 15\n  # ) +\n  scale_colour_manual(values = col_groups, guide = \"none\") +\n  scale_size_continuous(range = c(0, 3), guide = \"none\")\n\np_1\n\n\n\n\n\nFigure 1.7: Empirical counterfactual of \\(\\mathbf{x}_{\\textcolor{red}{0},1}\\) (blue square) and path to the counterfactual obtained with Gaussian optimal transport on the simplex (shown with the red line).\n\n\n\n\n\n\n\n\nFor illustrative purposes, we can also visualize the counterfactual of another observation, e.g., the third.\nThe counterfactual obtained with the optimal transport using LP libraries:\n\ni &lt;- 3\nweights_i &lt;- M0[i,]\ncounterfactual_i &lt;- weights_i %*% tP1\ncounterfactual_i\n\n             A         B         C\n[1,] 0.2011471 0.6590863 0.1397667\n\n\nAnd the version obtained with Gaussian OT:\n\ngaussian_t_obs_i &lt;- transp_val_clr_0_1[i, ]\ngaussian_t_obs_i_interp &lt;- interpolated(transp_val_clr_0_1)[[i]]\ngaussian_t_obs_i\n\n# A tibble: 1 × 3\n      A     B     C\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.204 0.659 0.138\n\n\n\n\nCodes to create the Figure.\np_2 &lt;- ggtern(\n  data = toydataset |&gt; filter(group == 0), \n  mapping = aes(x = A, y = C, z = B, colour = group)\n) +\n  geom_point(size = .2) +\n  # Focus on the first obs in group 0\n  geom_point(\n    data = toydataset |&gt; filter(group == 0) |&gt; slice(!!i),\n    size = 3\n  ) +\n  # Display observations in group 1 where size is function of the\n  # obtained weight\n  geom_point(\n    data = toydataset |&gt; filter(group == 1) |&gt;\n      mutate(weight = M0[i,]),\n    mapping = aes(size = weight),\n    alpha = .5\n  ) +\n  # Display the counterfactual\n  geom_point(\n    data = gaussian_t_obs_i |&gt; \n      mutate(\n        group = factor(1, levels = c(0, 1)), \n        colour = factor(col_groups[[\"1\"]], levels = levels(toydataset$colour))\n      ),\n    size = 2,\n    shape = 15\n  ) +\n  # Display the interpolation path obtained with Gaussian OT\n  geom_line(\n    data = gaussian_t_obs_i_interp |&gt; \n      mutate(\n        group = factor(0, levels = c(0, 1)), \n        colour = factor(col_groups[[\"0\"]], levels = levels(toydataset$colour))\n      ),\n    linewidth = 1\n  ) +\n  scale_colour_manual(values = col_groups, guide = \"none\") +\n  scale_size_continuous(range = c(0, 3), guide = \"none\")\n\np_2\n\n\n\n\n\nFigure 1.8: Empirical counterfactual of \\(\\mathbf{x}_{\\textcolor{red}{0},3}\\) (blue square) and path to the counterfactual obtained with Gaussian optimal transport on the simplex (shown with the red line).\n\n\n\n\n\n\n\n\nLastly, we can build a small function, counterfactual_w(), to compute the counterfactuals for all observations from group 0 to group 1.\n\n#' Builds counterfactuals of observations from group 0 to group 1 using an\n#' estimated mapping.\n#'\n#' @param mapping Wasserstein mapping between the two sets of probability\n#'  vectors\n#' @param X0 Matrix (or data frame) with vectors of probabilities in group 0.\n#' @param X1 Matrix (or data frame) with vectors of probabilities in group 1.\n#'\n#' @returns A matrix with the counterfactual values using the mapping.\ncounterfactual_w &lt;- function(mapping,\n                             X0,\n                             X1) {\n  if (!is.matrix(X0)) X0 &lt;- as.matrix(X0)\n  if (!is.matrix(X1)) X1 &lt;- as.matrix(X1)\n  M0 &lt;- mapping$plan * nrow(X0)\n\n  M0 %*% X1\n}\n\nThis function can easily be applied:\n\ncounterfactuals &lt;- counterfactual_w(mapping = W_xy, X0 = X0, X1 = X1)\nhead(counterfactuals)\n\n             A         B          C\n[1,] 0.3167699 0.4324855 0.25074451\n[2,] 0.3187466 0.4655385 0.21571490\n[3,] 0.2011471 0.6590863 0.13976667\n[4,] 0.1858224 0.7171117 0.09706588\n[5,] 0.3199079 0.4288071 0.25128509\n[6,] 0.2426826 0.4549539 0.30236351\n\n\n\n\n\n\nBrualdi, Richard A. 2006. Combinatorial Matrix Classes. Vol. 13. Cambridge University Press.\n\n\nMcCann, Robert J. 1997. “A Convexity Principle for Interacting Gases.” Advances in Mathematics 128 (1): 153–79.\n\n\nPal, Soumik, and Ting-Kam Leonard Wong. 2016. “The Geometry of Relative Arbitrage.” Mathematics and Financial Economics 10: 263–93.\n\n\n———. 2018. “Exponentially Concave Functions and a New Information Geometry.” The Annals of Probability 46 (2): 1070–1113.\n\n\n———. 2020. “Multiplicative Schrödinger Problem and the Dirichlet Transport.” Probability Theory and Related Fields 178 (1): 613–54.\n\n\nPeyré, Gabriel, Marco Cuturi, et al. 2019. “Computational Optimal Transport: With Applications to Data Science.” Foundations and Trends in Machine Learning 11 (5-6): 355–607.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Toy dataset</span>"
    ]
  },
  {
    "objectID": "application-german-credit.html",
    "href": "application-german-credit.html",
    "title": "2  German Credit Dataset",
    "section": "",
    "text": "2.1 The Dataset\nThe dataset is available in the {fairml} package.\ndata(german.credit, package = \"fairml\")\nstr(german.credit)\n\n'data.frame':   1000 obs. of  21 variables:\n $ Account_status          : Factor w/ 4 levels \"&lt; 0 DM\",\"&gt;= 200 DM\",..: 1 3 4 1 1 4 4 3 4 3 ...\n $ Duration                : num  6 48 12 42 24 36 24 36 12 30 ...\n $ Credit_history          : Factor w/ 5 levels \"all credits at this bank paid back duly\",..: 2 4 2 4 3 4 4 4 4 2 ...\n $ Purpose                 : Factor w/ 10 levels \"business\",\"car (new)\",..: 8 8 5 6 2 5 6 3 8 2 ...\n $ Credit_amount           : num  1169 5951 2096 7882 4870 ...\n $ Savings_bonds           : Factor w/ 5 levels \"&lt; 100 DM\",\"&gt;= 1000 DM\",..: 5 1 1 1 1 5 4 1 2 1 ...\n $ Present_employment_since: Factor w/ 5 levels \"&lt; 1 year\",\"&gt;= 7 years\",..: 2 3 4 4 3 3 2 3 4 5 ...\n $ Installment_rate        : num  4 2 2 2 3 2 3 2 2 4 ...\n $ Other_debtors_guarantors: Factor w/ 3 levels \"co-applicant\",..: 3 3 3 2 3 3 3 3 3 3 ...\n $ Resident_since          : num  4 2 3 4 4 4 4 2 4 2 ...\n $ Property                : Factor w/ 4 levels \"building society savings agreement / life insurance\",..: 3 3 3 1 4 4 1 2 3 2 ...\n $ Age                     : num  67 22 49 45 53 35 53 35 61 28 ...\n $ Other_installment_plans : Factor w/ 3 levels \"bank\",\"none\",..: 2 2 2 2 2 2 2 2 2 2 ...\n $ Housing                 : Factor w/ 3 levels \"rent\",\"own\",\"for free\": 2 2 2 3 3 3 2 1 2 2 ...\n $ Existing_credits        : num  2 1 1 1 2 1 1 1 1 2 ...\n $ Job                     : Factor w/ 4 levels \"management / self-employed / highly qualified employee / officer\",..: 2 2 4 2 2 4 2 1 4 1 ...\n $ People_maintenance_for  : num  1 1 2 2 2 2 1 1 1 1 ...\n $ Telephone               : Factor w/ 2 levels \"none\",\"yes\": 2 1 1 1 1 2 1 2 1 1 ...\n $ Foreign_worker          : Factor w/ 2 levels \"no\",\"yes\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Credit_risk             : Factor w/ 2 levels \"BAD\",\"GOOD\": 2 1 2 2 1 2 2 2 2 1 ...\n $ Gender                  : Factor w/ 2 levels \"Female\",\"Male\": 1 2 1 1 1 1 1 1 1 1 ...\nWe want to transport the Purpose variable, which has 10 different levels in the dataset. To be able to visualize the transport, we merge some of the classes together to obtain three main purposes: cars, equipment, and other.\ngerman.credit &lt;- \n  german.credit |&gt; \n  mutate(\n    Purpose = case_when(\n      Purpose %in% c(\"car (new)\",\"car (used)\") ~ \"cars\",\n      Purpose %in% c(\n        \"domestic appliances\", \"furniture / equipment\", \"radio / television\"\n      ) ~ \"equipment\",\n      TRUE ~ \"other\"\n    ) |&gt; as.factor()\n  )",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>German Credit Dataset</span>"
    ]
  },
  {
    "objectID": "application-german-credit.html#estimation-of-scores",
    "href": "application-german-credit.html#estimation-of-scores",
    "title": "2  German Credit Dataset",
    "section": "2.2 Estimation of Scores",
    "text": "2.2 Estimation of Scores\nWe fit four models, \\(\\widehat{m}^{(k)}(\\mathbf{x}_j|\\mathbf{x}_{-j})\\), using a multinomial loss, yielding predicted scores \\(\\widehat{\\mathbf{x}}_{j}^{(k)}\\in\\mathcal{S}_d\\) for \\(k \\in \\{1,2,3,4\\}\\). The sensitive attribute \\(s\\) and the credit risk variable (Bad/Good)–typically the target variable in this dataset but not in our case–are excluded from estimation. The four models are:\n\nGAM-MLR (1): A multinomial model with splines for three continuous variables.\nGAM-MLR (2): A multinomial model with splines for three continuous variables and seven additional predictors.\nRandom Forest: A classifier using all available variables.\nGradient Boosting Model: A GBM trained on all available variables.\n\nThe estimation of GAM-MLR (1):\n\nlibrary(splines)\nrequire(nnet)\n\nLoading required package: nnet\n\nset.seed(123)\nmodel_glm_1 &lt;- multinom(\n  Purpose ~ bs(Credit_amount) + bs(Age) + bs(Duration), \n  data = german.credit\n)\n\n# weights:  33 (20 variable)\ninitial  value 1098.612289 \niter  10 value 984.769274\niter  20 value 982.287732\nfinal  value 982.287248 \nconverged\n\n\nThe estimation of GAM-MLR (2):\n\nmodel_glm_2 &lt;- multinom(\n  Purpose ~ bs(Credit_amount) + bs(Age) + bs(Duration) +\n    Present_employment_since + Savings_bonds + Property + Account_status + \n    Credit_history + Resident_since + Job + Housing,\n  data = german.credit,\n)\n\n# weights:  105 (68 variable)\ninitial  value 1098.612289 \niter  10 value 955.629654\niter  20 value 934.033840\niter  30 value 931.711611\niter  40 value 930.922840\niter  50 value 930.662446\niter  60 value 930.649598\nfinal  value 930.649264 \nconverged\n\n\nThe estimation of the random forest:\n\nlibrary(randomForest)\nmodel_rf &lt;- randomForest(Purpose ~ ., data = german.credit[, -c(20,21)])\n\nThe estimation of the gradient boosting model:\n\nlibrary(gbm)\nlibrary(caret)\nmodel_gbm &lt;- gbm(\n  Purpose ~ .,\n  data = german.credit[, -c(20,21)],\n  distribution = \"multinomial\",\n  cv.folds = 10,\n  shrinkage = .01,\n  n.minobsinnode = 10,\n  n.trees = 2000\n)\n\nNow that we have estimated the four models, we can extract the estimates scores \\(\\widehat{\\mathbf{x}}_{j}^{(k)}\\in\\mathcal{S}_d\\):\n\nscores_glm_1 &lt;- predict(model_glm_1, type = \"probs\")\nscores_glm_2 &lt;- predict(model_glm_2, type = \"probs\")\nscores_rf &lt;- predict(model_rf, type = \"prob\")\nscores_gbm &lt;- predict.gbm(\n  object = model_gbm,\n  newdata = german.credit[, -c(20,21)],\n  n.trees = 2000,\n  type = \"response\"\n)\nscores_gbm &lt;- scores_gbm[ , , 1]\n\nLet us have a look at the predicted scores of four individuals (2 women, 2 men), for each model.\n\n\nCodes to create the Table.\nprint_highlighted_obs &lt;- function(scores) {\n  ind_highlight &lt;- c(2, 5, 13, 8)\n  tb &lt;- german.credit |&gt;\n    select(Purpose, Gender) |&gt; \n    bind_cols(scores) |&gt; \n    slice(ind_highlight)\n  row.names(tb) &lt;- NULL\n  tb\n}\n\ntb_four_indiv &lt;- \n  print_highlighted_obs(scores_glm_1) |&gt; mutate(model = \"glm_1\") |&gt; \n  bind_rows(\n    print_highlighted_obs(scores_glm_2) |&gt; mutate(model = \"glm_2\")\n  ) |&gt; \n  bind_rows(\n    print_highlighted_obs(scores_rf) |&gt; mutate(model = \"rf\")\n  ) |&gt; \n  bind_rows(\n    print_highlighted_obs(scores_gbm) |&gt; mutate(model = \"gbm\")\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n                 \"Gradient Boosting Model\")\n    )\n  ) |&gt; \n  relocate(model, .before = Purpose)\n\ntb_four_indiv |&gt; select(-model) |&gt; \n  kableExtra::kbl(\n    booktabs = TRUE, digits = 4,\n  ) |&gt; \n  kableExtra::kable_paper() |&gt; \n  kableExtra::add_header_above(c(\" \" = 2, \"Predicted Scores\" = 3)) |&gt; \n  kableExtra::pack_rows(index = table(tb_four_indiv$model))\n\n\n\n\nTable 2.1: Mappings from the purpose categorical variable \\(x\\) to the compositional one \\(\\tilde{\\mathbf{x}}\\), for four individuals of the dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicted Scores\n\n\n\nPurpose\nGender\ncars\nequipment\nother\n\n\n\n\nGAM-MLR(1)\n\n\nequipment\nMale\n0.1838\n0.6156\n0.2006\n\n\ncars\nFemale\n0.4086\n0.4238\n0.1676\n\n\nequipment\nMale\n0.1941\n0.7082\n0.0977\n\n\ncars\nFemale\n0.4704\n0.2683\n0.2613\n\n\nGAM-MLR(2)\n\n\nequipment\nMale\n0.0922\n0.7592\n0.1486\n\n\ncars\nFemale\n0.4680\n0.2406\n0.2914\n\n\nequipment\nMale\n0.1123\n0.7907\n0.0971\n\n\ncars\nFemale\n0.5074\n0.2698\n0.2228\n\n\nRandom Forest\n\n\nequipment\nMale\n0.2265\n0.4972\n0.2762\n\n\ncars\nFemale\n0.3457\n0.3138\n0.3404\n\n\nequipment\nMale\n0.1685\n0.7609\n0.0707\n\n\ncars\nFemale\n0.4492\n0.3476\n0.2032\n\n\nGradient Boosting Model\n\n\nequipment\nMale\n0.0999\n0.6904\n0.2097\n\n\ncars\nFemale\n0.5859\n0.1415\n0.2725\n\n\nequipment\nMale\n0.1137\n0.7613\n0.1250\n\n\ncars\nFemale\n0.5011\n0.2523\n0.2466",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>German Credit Dataset</span>"
    ]
  },
  {
    "objectID": "application-german-credit.html#optimal-transport-in-the-euclidean-representation",
    "href": "application-german-credit.html#optimal-transport-in-the-euclidean-representation",
    "title": "2  German Credit Dataset",
    "section": "2.3 Optimal Transport in the Euclidean Representation",
    "text": "2.3 Optimal Transport in the Euclidean Representation\nWe can now apply Algorithm 1.1 with a Gaussian mapping in an Euclidean representation space to transport from observed \\(\\widehat{\\mathbf{x}}_j|s=0\\) (scores for women) to counterfactual \\(\\widehat{\\mathbf{x}}_j|s=1\\) (scores for men), in \\(\\mathcal{S}_d\\).\nLet us isolate women and men:\n\nind_0 &lt;- which(german.credit$Gender == \"Female\")\nind_1 &lt;- which(german.credit$Gender == \"Male\")\n\nThen, we create matrices for each model with the predicted scores for each category, i.e., the representation of the categorical variable Purpose in the unit simplex.\n\n# GAM-MLR(1)\nX0_glm_1 &lt;- scores_glm_1[ind_0,]\nX1_glm_1 &lt;- scores_glm_1[ind_1,]\n# GAM-MLR(2)\nX0_glm_2 &lt;- scores_glm_2[ind_0,]\nX1_glm_2 &lt;- scores_glm_2[ind_1,]\n# RF\nX0_rf &lt;- scores_rf[ind_0,]\nX1_rf &lt;- scores_rf[ind_1,]\n# GBM\nX0_gbm &lt;- scores_gbm[ind_0,]\nX1_gbm &lt;- scores_gbm[ind_1,]\n\nThen, we can apply Algorithm 1.1 to each set of predicted scores. We use the clr transform and Gaussian OT:\n\ntransp_glm_1 &lt;- transport_simplex(X0 = X0_glm_1, X1 = X1_glm_1, n_interp = 31)\ntransp_glm_2 &lt;- transport_simplex(X0 = X0_glm_2, X1 = X1_glm_2, n_interp = 31)\ntransp_rf &lt;- transport_simplex(X0 = X0_rf, X1 = X1_rf, n_interp = 31)\ntransp_gbm &lt;- transport_simplex(X0 = X0_rf, X1 = X1_gbm, n_interp = 31)\n\nWe can then have a look at the percentage of each purpose category in the initial dataset, compare it with the average predicted score of each category for each model, and with the average of the transported predicted score for women.\n\n\nCodes to create the Table.\n# Proportions of each purpose level by gender in the dataset\nprop_purposes &lt;- \n  german.credit |&gt; \n  count(Purpose, Gender) |&gt; \n  group_by(Gender) |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  select(-n) |&gt; \n  pivot_wider(names_from = Purpose, values_from = prop) |&gt; \n  mutate(type = \"Categorical\")\n\nget_table_pred_transp &lt;- function(scores, transp_scores) {\n  # Average predicted scores for each purpose level by gender\n  mean_scores_by_gender &lt;- \n    german.credit |&gt; \n    select(Purpose, Gender) |&gt; \n    bind_cols(scores) |&gt; \n    group_by(Gender) |&gt; \n    summarise(across(colnames(!!scores), ~mean(.x))) |&gt; \n    mutate(type = \"Composition\")\n  \n  # Average predicted transported score of women for each purpose level\n  mean_transp_scores_women &lt;- colMeans(transp_scores) |&gt; \n    as_tibble_row() |&gt;\n    mutate(type = \"Transported\", Gender = \"Female -&gt; Male\")\n  \n  mean_scores_by_gender |&gt; \n    bind_rows(mean_transp_scores_women)\n}\n\ntb_pred_transp_mean &lt;-\n  prop_purposes |&gt; mutate(model = \"obs\") |&gt; \n  bind_rows(\n    get_table_pred_transp(scores_glm_1, transp_glm_1) |&gt; mutate(model = \"glm_1\")\n  ) |&gt; \n  bind_rows(\n    get_table_pred_transp(scores_glm_2, transp_glm_2) |&gt; mutate(model = \"glm_2\")\n  ) |&gt; \n  bind_rows(\n    get_table_pred_transp(scores_rf, transp_rf) |&gt; mutate(model = \"rf\")\n  ) |&gt; \n  bind_rows(\n    get_table_pred_transp(scores_gbm, transp_gbm) |&gt; mutate(model = \"gbm\")\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  ) |&gt; \n  relocate(model, .before = Gender) |&gt; \n  relocate(type, .after = model)\n\ntb_pred_transp_mean |&gt; select(-model) |&gt; \n  kableExtra::kbl(\n  booktabs = TRUE, digits = 4,\n) |&gt; \n  kableExtra::kable_paper() |&gt; \n  kableExtra::add_header_above(c(\" \" = 2, \"Purposes\" = 3)) |&gt; \n  kableExtra::pack_rows(index = table(tb_pred_transp_mean$model))\n\n\n\n\nTable 2.2: Optimal transport using the \\(\\operatorname{clr}\\) transformation, and Gaussian optimal transports, on the scores in the database, with two logistic GAM models to predict scores, a random forest, and a boosting model. For observed values, the observed proportions of purpose categories are reported by gender. Then, for each model, the average of predicted scores by gender for each categories are shown (Composition). Lastly, the average of transported predicted scores for women are reported (Transported).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPurposes\n\n\n\ntype\nGender\ncars\nequipment\nother\n\n\n\n\nObserved Values\n\n\nCategorical\nFemale\n0.3522\n0.4464\n0.2014\n\n\nCategorical\nMale\n0.3032\n0.5323\n0.1645\n\n\nGAM-MLR(1)\n\n\nComposition\nFemale\n0.3487\n0.4549\n0.1964\n\n\nComposition\nMale\n0.3111\n0.5133\n0.1757\n\n\nTransported\nFemale -&gt; Male\n0.3102\n0.5142\n0.1757\n\n\nGAM-MLR(2)\n\n\nComposition\nFemale\n0.3448\n0.4584\n0.1967\n\n\nComposition\nMale\n0.3195\n0.5054\n0.1751\n\n\nTransported\nFemale -&gt; Male\n0.3185\n0.5057\n0.1758\n\n\nRandom Forest\n\n\nComposition\nFemale\n0.3521\n0.4519\n0.1960\n\n\nComposition\nMale\n0.3223\n0.4986\n0.1791\n\n\nTransported\nFemale -&gt; Male\n0.3233\n0.4969\n0.1798\n\n\nGradient Boosting Model\n\n\nComposition\nFemale\n0.3452\n0.4553\n0.1995\n\n\nComposition\nMale\n0.3147\n0.5118\n0.1735\n\n\nTransported\nFemale -&gt; Male\n0.3168\n0.5086\n0.1746\n\n\n\n\n\n\n\n\n\n\n\n2.3.1 Visualization of Transported Categories\nWe can then show the counterfactuals on a ternary plot, and graph the displacement interpolation when generationg from the factual (women) to the counterfactuals (men).\nFirst, we format the paths:\n\ntransp_glm_1_path &lt;- interpolated(transp_glm_1) |&gt; \n  list_rbind(names_to = \"id_obs\")\ntransp_glm_2_path &lt;- interpolated(transp_glm_2) |&gt; \n  list_rbind(names_to = \"id_obs\")\ntransp_rf_path &lt;- interpolated(transp_rf) |&gt; \n  list_rbind(names_to = \"id_obs\")\ntransp_gbm_path &lt;- interpolated(transp_gbm) |&gt; \n  list_rbind(names_to = \"id_obs\")\n\nThen, we can show, for each model, the representation in the simplex of the categorical variable Purpose, by gender (women in red and men in blue), as well as the displacement interpolation.\n\n\nCodes to create the Figure.\nscores_all &lt;- as_tibble(scores_glm_1) |&gt; \n  mutate(Gender = german.credit$Gender, model = \"glm_1\") |&gt; \n  bind_rows(\n    as_tibble(scores_glm_2) |&gt; \n      mutate(Gender = german.credit$Gender, model = \"glm_2\")\n  ) |&gt; \n  bind_rows(\n    as_tibble(as.data.frame(scores_rf)) |&gt; \n      mutate(Gender = german.credit$Gender, model = \"rf\")\n  ) |&gt; \n  bind_rows(\n    as_tibble(scores_gbm) |&gt; \n      mutate(Gender = german.credit$Gender, model = \"gbm\")\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  )\n\ntransp_all_path &lt;- \n  transp_glm_1_path |&gt; \n  mutate(\n    Gender = factor(\"Female\", levels = levels(german.credit$Gender)),\n    model = \"glm_1\"\n  ) |&gt; \n  bind_rows(\n    transp_glm_2_path |&gt; \n      mutate(\n        Gender = factor(\"Female\", levels = levels(german.credit$Gender)),\n        model = \"glm_2\"\n      ) \n  ) |&gt; \n  bind_rows(\n    transp_rf_path |&gt; \n      mutate(\n        Gender = factor(\"Female\", levels = levels(german.credit$Gender)),\n        model = \"rf\"\n      ) \n  ) |&gt; \n  bind_rows(\n    transp_gbm_path |&gt; \n      mutate(\n        Gender = factor(\"Female\", levels = levels(german.credit$Gender)),\n        model = \"gbm\"\n      ) \n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  )\n\nggtern(\n  data = scores_all,\n  mapping = aes(x = cars, y = other, z = equipment, colour = Gender)\n) +\n  geom_point(size = .1) +\n  geom_line(\n    data = transp_all_path, \n    linewidth = .2, alpha = .8,\n    mapping = aes(group = id_obs)\n  ) +\n  scale_colour_manual(values = c(\"Female\" = \"red\", \"Male\" = \"blue\"), guide = \"none\") +\n  facet_wrap(~model) +\n  labs(x = \"Cars\", y = \"Other\", z = \"Equip.\") +\n  theme_paper()\n  # theme(\n  #   tern.axis.title = element_text(size = rel(.9))\n  # )\n\n\n\n\n\nFigure 2.1: Optimal Transport using clr transform. Points in red are compositions for women, whereas points in blue are compositions for men. The lines indicate the displacement interpolation when generating counterfactuals.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>German Credit Dataset</span>"
    ]
  },
  {
    "objectID": "application-german-credit.html#optimal-transport-in-mathcals_3",
    "href": "application-german-credit.html#optimal-transport-in-mathcals_3",
    "title": "2  German Credit Dataset",
    "section": "2.4 Optimal Transport in \\(\\mathcal{S}_3\\)",
    "text": "2.4 Optimal Transport in \\(\\mathcal{S}_3\\)\nLet us now use Algorithm 1.2 to create counterfactuals using matching in \\(\\mathcal{S}_3\\).\nTo that end, we use the wasserstein_simplex() function from our package.\n\n\n\n\n\n\nNote\n\n\n\nThe codes are a bit long to run (about 40 seconds for each model on a 2023 MacBook Pro with an M2 chip). Here, we load results saved from a previously evaluated code.\n\n\n\nmapping_glm_1 &lt;- wasserstein_simplex(X0_glm_1, X1_glm_1)\nmapping_glm_2 &lt;- wasserstein_simplex(X0_glm_2, X1_glm_2)\nmapping_rf &lt;- wasserstein_simplex(X0_rf, X1_rf)\nmapping_gbm &lt;- wasserstein_simplex(X0_gbm, X1_gbm)\n\nif (!dir.exists(\"../output/\")) dir.create(\"../output/\", recursive = TRUE)\nsave(\n  mapping_glm_1, mapping_glm_2, mapping_rf, mapping_gbm,\n  file = \"../output/matching_german.rda\"\n)\n\n\nload(\"../output/matching_german.rda\")\n\nWe extract the estimated weights for all the individuals:\n\nM0_glm_1 &lt;- mapping_glm_1$plan * nrow(X0_glm_1)\nM0_glm_2 &lt;- mapping_glm_2$plan * nrow(X0_glm_2)\nM0_rf &lt;- mapping_rf$plan * nrow(X0_rf)\nM0_gbm &lt;- mapping_gbm$plan * nrow(X0_gbm)\n\nLet us focus on a single individual \\(x_{0,i}=\\):\n\ni &lt;- 34\n\nFor each model, we extract the representation of the Purpose characteristic in the simplex (i.e., the predicted scores by the \\(k\\)-th model, \\(\\widehat{m}^{(k)}(\\mathbf{x}_j|\\mathbf{x}_{-j})\\)). Let us denote this composition as \\(\\mathbf{x}_{0,i}^{(k)}\\)\n\nindiv_i_glm_1 &lt;- X0_glm_1[i, ]\nindiv_i_glm_2 &lt;- X0_glm_2[i, ]\nindiv_i_rf &lt;- X0_rf[i, ]\nindiv_i_gbm &lt;- X0_gbm[i, ]\n\nWe then extract the weights \\(\\mathbf{P}^{\\star(k)}_i\\):\n\nweights_i_glm_1 &lt;- M0_glm_1[i, ]\nweights_i_glm_2 &lt;- M0_glm_2[i, ]\nweights_i_rf &lt;- M0_rf[i, ]\nweights_i_gbm &lt;- M0_gbm[i, ]\n\nLastly, we compute, for our individual, its counterfactual \\(T^\\star(\\mathbf{x}_{0,i})\\), by simply computing the weighted average of the characteristics of the individuals from the other group.\n\ncfact_i_glm_1 &lt;- weights_i_glm_1 %*% X1_glm_1\ncfact_i_glm_2 &lt;- weights_i_glm_2 %*% X1_glm_2\ncfact_i_rf &lt;- weights_i_rf %*% X1_rf\ncfact_i_gbm &lt;- weights_i_gbm %*% X1_gbm\n\nWe can then plot (Figure 3.2) the representation of the woman of interest obtained for each model (red dot), and its counterfactual obtained by matching (blue dot). We also plot, on the ternary plot, all the women and men. The size of the dots for men is proportional to the weights corresponding to the women of interest.\n\n\nCodes to create the Figure.\n# Women\ntb_plot_females &lt;- \n  as_tibble(X0_glm_1) |&gt; \n  mutate(Gender = \"Female\", model = \"glm_1\") |&gt; \n  bind_rows(\n    as_tibble(X0_glm_2) |&gt; \n      mutate(Gender = \"Female\", model = \"glm_2\")\n  ) |&gt; \n  bind_rows(\n    as_tibble(X0_rf) |&gt; \n      mutate(Gender = \"Female\", model = \"rf\")\n  ) |&gt; \n  bind_rows(\n    as_tibble(X0_gbm) |&gt; \n      mutate(Gender = \"Female\", model = \"gbm\",)\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  )\n\n# Males individuals, with a column weights_i giving their weight used to \n# construct the counterfactual for indiv i\ntb_plot_males &lt;- \n  as_tibble(X1_glm_1) |&gt; \n  mutate(\n    Gender = \"Male\", model = \"glm_1\", weights_i = weights_i_glm_1\n  ) |&gt; \n  bind_rows(\n    as_tibble(X1_glm_2) |&gt; \n      mutate(\n        Gender = \"Male\", model = \"glm_2\", weights_i = weights_i_glm_2\n      )\n  ) |&gt; \n  bind_rows(\n    as_tibble(X1_rf) |&gt; \n      mutate(\n        Gender = \"Male\", model = \"rf\", weights_i = weights_i_rf\n      )\n  ) |&gt; \n  bind_rows(\n    as_tibble(X1_gbm) |&gt; \n      mutate(\n        Gender = \"Male\", model = \"gbm\", weights_i = weights_i_rf\n      )\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  )\n\nindiv_i &lt;- \n  as_tibble_row(indiv_i_glm_1) |&gt; mutate(Gender = \"Female\", model = \"glm_1\") |&gt; \n  bind_rows(\n    as_tibble_row(indiv_i_glm_2) |&gt; mutate(Gender = \"Female\", model = \"glm_2\")\n  ) |&gt; \n  bind_rows(\n    as_tibble_row(indiv_i_rf) |&gt; mutate(Gender = \"Female\", model = \"rf\")\n  ) |&gt; \n  bind_rows(\n    as_tibble_row(indiv_i_gbm) |&gt; mutate(Gender = \"Female\", model = \"gbm\")\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  )\n\ncfact_indiv_i &lt;- \n  as_tibble(cfact_i_glm_1) |&gt; mutate(Gender = \"Male\", model = \"glm_1\") |&gt; \n  bind_rows(\n    as_tibble(cfact_i_glm_2) |&gt; mutate(Gender = \"Male\", model = \"glm_2\")\n  ) |&gt; \n  bind_rows(\n    as_tibble(cfact_i_rf) |&gt; mutate(Gender = \"Male\", model = \"rf\")\n  ) |&gt; \n  bind_rows(\n    as_tibble(cfact_i_gbm) |&gt; mutate(Gender = \"Male\", model = \"gbm\")\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  )\n\nggtern(\n  mapping = aes(x = cars, y = other, z = equipment, colour = Gender)\n) +\n  geom_point(\n    data = tb_plot_females,\n    size = .1,\n    alpha = .6\n  ) +\n  geom_point(\n    data = tb_plot_males |&gt; \n      group_by(model) |&gt; \n      mutate(high = weights_i &gt; quantile(weights_i, probs = .995)), \n    mapping = aes(size = weights_i, alpha = high),\n  ) +\n  geom_point(data = indiv_i, size = 3, colour = \"white\") +\n  geom_point(data = indiv_i, size = 2) +\n  geom_point(data = cfact_indiv_i, size = 3, colour = \"white\", shape = 15) +\n  geom_point(data = cfact_indiv_i, size = 2, shape = 15) +\n  facet_wrap(~model) +\n  labs(x = \"Cars\", y = \"Other\", z = \"Equip.\") +\n  scale_colour_manual(\n    values = c(\"Female\" = \"red\", \"Male\" = \"blue\"), guide = \"none\"\n  ) +\n  scale_size_continuous(range = c(0, 2), guide = \"none\") +\n  scale_alpha_discrete(guide = \"none\") +\n  theme_paper()\n\n\n\n\n\nFigure 2.2: Empirical matching of a woman \\(\\mathbf{x}_{0,i}^{(k)}\\) (big red dot) with men (blue dots). The Size of blue dots are proportional to the weights \\(\\mathbf{P}^\\star_i\\). The counterfactual obtained with matching \\(T^\\star(\\mathbf{x}_{0,i})\\) is shown as a blue square.\n\n\n\n\n\n\n\n\nTo finish, let us look more closely to the i-th woman for which we have shown the counterfactual on the ternary plot. The value of the Purpose variable for her is other:\n\ngerman.credit[ind_0[i], \"Purpose\"]\n\n[1] other\nLevels: cars equipment other\n\n\nUsing the GAM-MLR(2) model, we obtained the following composition:\n\nX0_glm_2[i, ]\n\n     cars equipment     other \n0.3697923 0.2381080 0.3920997 \n\n\nThe closest points in the group of men, obtained using Algorithm 1.2 are:\n\nind_close_points &lt;- tail(order(weights_i_glm_2), 3)\nX1_glm_2[ind_close_points, ] |&gt; \n  as_tibble() |&gt; \n  mutate(\n    Purpose = german.credit[ind_1[ind_close_points], ] |&gt; select(Purpose),\n    index = ind_close_points,\n    weights_i = weights_i_glm_2[ind_close_points]) |&gt; \n  arrange(desc(weights_i)) |&gt; \n  kableExtra::kbl(booktabs = TRUE) |&gt; \n  kableExtra::kable_paper()\n\n\n\n\ncars\nequipment\nother\nPurpose\nindex\nweights_i\n\n\n\n\n0.3627510\n0.2817122\n0.3555368\nother\n168\n0.5483871\n\n\n0.3993449\n0.3155724\n0.2850827\nother\n133\n0.2258065\n\n\n0.4232457\n0.2865582\n0.2901962\nequipment\n275\n0.2258065\n\n\n\n\n\n\n\nFor the first two closest men, \\(x_{1,j}=\\) other. So, it would make sense to suppose that the counterfactual version of woman \\(i\\) with an “other” credit is a man with the same purpose.\nThe counterfactual version for the composition is:\n\ncfact_i_glm_2\n\n          cars equipment     other\n[1,] 0.3846742 0.2904523 0.3248735\n\n\nThe counterfactual categorical value would thus be:\n\ncolnames(cfact_i_glm_2)[which.max(cfact_i_glm_2)]\n\n[1] \"cars\"\n\n\nFor comparison, using Gaussian OT, the counterfactual would be:\n\ntransp_glm_2 |&gt; slice(i)\n\n# A tibble: 1 × 3\n   cars equipment other\n  &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 0.347     0.286 0.368\n\n\n\n\n\n\nHofmann, H. 1994. “German Credit Data.” UCI Machine Learning Repository. https://doi.org/10.24432/C5NC77.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>German Credit Dataset</span>"
    ]
  },
  {
    "objectID": "application-adult.html",
    "href": "application-adult.html",
    "title": "3  Adult Dataset",
    "section": "",
    "text": "3.1 The Dataset\nlibrary(fairml)\ndata(adult)\nWe want to build counterfactual values for the variable The categorical variable for which we want to build counterfactuals for the marital_status variable for women, had they been men. These are the raw categories:\nadult |&gt; pull(marital_status) |&gt; table()\n\n\n   Married-civ-spouse              Divorced         Never-married \n                14065                  4214                  9726 \n            Separated               Widowed Married-spouse-absent \n                  939                   827                   370 \n    Married-AF-spouse \n                   21\nLet us regroup these categories in three: (i) married, (ii) never married, (iii) separated.\nadult &lt;- \n  adult |&gt; \n  mutate(\n    marital_status = case_when(\n      marital_status %in% c(\n        \"Married-AF-spouse\", \"Married-civ-spouse\"\n      ) ~ \"Married\",\n      marital_status %in% c(\n        \"Divorced\", \"Separated\", \"Widowed\", \"Married-spouse-absent\"\n      ) ~ \"Separated\",\n      marital_status %in% c(\"Never-married\") ~ \"Never-married\",\n      TRUE ~ \"error\"\n    ),\n    marital_status = factor(marital_status)\n  )\nThe global proportions in the dataset for each category of marital status:\nprop.table(adult |&gt; pull(marital_status) |&gt; table())\n\n\n      Married Never-married     Separated \n    0.4670115     0.3224587     0.2105298\nAnd if we compare by gender:\nCodes to create the Table.\nprop_marital &lt;- \n  adult |&gt; \n  count(sex, marital_status) |&gt; \n  group_by(sex) |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  select(-n) |&gt; \n  pivot_wider(names_from = marital_status, values_from = prop)\nprop_marital |&gt; \n  kableExtra::kbl(\n    booktabs = TRUE, digits = 4,\n  ) |&gt; \n  kableExtra::kable_paper() |&gt; \n  kableExtra::add_header_above(c(\" \" = 1, \"Proportions\" = 3))\n\n\n\n\nTable 3.1: Proportions of each marital status for women and for men.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProportions\n\n\n\nsex\nMarried\nNever-married\nSeparated\n\n\n\n\nFemale\n0.1525\n0.4408\n0.4067\n\n\nMale\n0.6180\n0.2657\n0.1164",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Adult Dataset</span>"
    ]
  },
  {
    "objectID": "application-adult.html#estimation-of-scores",
    "href": "application-adult.html#estimation-of-scores",
    "title": "3  Adult Dataset",
    "section": "3.2 Estimation of Scores",
    "text": "3.2 Estimation of Scores\nWe fit four models, \\(\\widehat{m}^{(k)}(\\mathbf{x}_j|\\mathbf{x}_{-j})\\), using a multinomial loss, yielding predicted scores \\(\\widehat{\\mathbf{x}}_{j}^{(k)}\\in\\mathcal{S}_d\\) for \\(k \\in \\{1,2,3,4\\}\\). The sensitive attribute \\(s\\). The income variable is also removed. The four models are:\n\nGAM-MLR (1): A multinomial model with splines for two continuous variables and a third variable.\nGAM-MLR (2): A multinomial model with adidtional variables.\nRandom Forest: A classifier using all available variables.\nGradient Boosting Model: A GBM trained on all available variables.\n\nThe estimation of GAM-MLR (1):\n\nlibrary(splines)\nrequire(nnet)\n\nLoading required package: nnet\n\nset.seed(123)\nmodel_glm_1 &lt;- multinom(\n  marital_status ~ bs(age) + bs(hours_per_week) + occupation, \n  data = adult |&gt; select(-sex, -income)\n)\n\n# weights:  63 (40 variable)\ninitial  value 33136.343851 \niter  10 value 25885.836959\niter  20 value 25131.762781\niter  30 value 24607.941350\niter  40 value 24439.499919\niter  50 value 24438.214321\nfinal  value 24438.207100 \nconverged\n\n\nThe estimation of GAM-MLR (2):\n\nmodel_glm_2 &lt;- multinom(\n  marital_status ~ bs(age) + bs(hours_per_week) + occupation + relationship +\n    workclass + bs(education_num) + education + bs(capital_gain),\n  data = adult |&gt; select(-sex, -income)\n)\n\n# weights:  144 (94 variable)\ninitial  value 33136.343851 \niter  10 value 9899.654429\niter  20 value 9211.159339\niter  30 value 8206.013535\niter  40 value 7892.102459\niter  50 value 7614.929161\niter  60 value 7450.099601\niter  70 value 7386.503591\niter  80 value 7371.425003\niter  90 value 7367.283292\niter 100 value 7367.014720\nfinal  value 7367.014720 \nstopped after 100 iterations\n\n\nThe estimation of the random forest:\n\nlibrary(randomForest)\n\n\nmodel_rf &lt;- randomForest(\n  marital_status ~ ., data = adult |&gt; select(-sex, -income)\n)\n\n\nsave(model_rf, file = \"../output/model_rf_adult.rda\")\n\n\nload( \"../output/model_rf_adult.rda\")\n\nThe estimation of the gradient boosting model:\n\nlibrary(gbm)\nlibrary(caret)\n\n\nmodel_gbm &lt;- gbm(\n  marital_status ~.,\n  data = adult |&gt; select(-sex, -income),\n  distribution = \"multinomial\",\n  cv.folds = 10,\n  shrinkage = .01,\n  n.minobsinnode = 10,\n  n.trees = 2000\n)\n\n\nsave(model_gbm, file = \"../output/model_gbm_adult.rda\")\n\n\nload( \"../output/model_gbm_adult.rda\")\n\nNow that we have estimated the four models, we can extract the estimates scores \\(\\widehat{\\mathbf{x}}_{j}^{(k)}\\in\\mathcal{S}_d\\):\n\nscores_glm_1 &lt;- predict(model_glm_1, type = \"probs\")\nscores_glm_2 &lt;- predict(model_glm_2, type = \"probs\")\nscores_rf &lt;- predict(model_rf, type = \"prob\")\nscores_gbm &lt;- predict.gbm(\n  object = model_gbm,\n  newdata = adult |&gt; select(-sex, -income),\n  n.trees = 2000,\n  type = \"response\")\nscores_gbm &lt;- scores_gbm[ , , 1]\n\nLet us have a look at the predicted scores of four individuals (2 women, 2 men), for each model.\n\n\nCodes to create the Table.\nprint_highlighted_obs &lt;- function(scores) {\n  ind_highlight &lt;- c(1, 2, 5, 6)\n  tb &lt;- adult |&gt;\n    select(marital_status, sex) |&gt; \n    bind_cols(scores) |&gt; \n    slice(ind_highlight)\n  row.names(tb) &lt;- NULL\n  tb\n}\n\ntb_four_indiv &lt;- \n  print_highlighted_obs(scores_glm_1) |&gt; mutate(model = \"glm_1\") |&gt; \n  bind_rows(\n    print_highlighted_obs(scores_glm_2) |&gt; mutate(model = \"glm_2\")\n  ) |&gt; \n  bind_rows(\n    print_highlighted_obs(scores_rf) |&gt; mutate(model = \"rf\")\n  ) |&gt; \n  bind_rows(\n    print_highlighted_obs(scores_gbm) |&gt; mutate(model = \"gbm\")\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n                 \"Gradient Boosting Model\")\n    )\n  ) |&gt; \n  relocate(model, .before = marital_status)\n\ntb_four_indiv |&gt; select(-model) |&gt; \n  kableExtra::kbl(\n    booktabs = TRUE, digits = 4,\n  ) |&gt; \n  kableExtra::kable_paper() |&gt; \n  kableExtra::add_header_above(c(\" \" = 2, \"Predicted Scores\" = 3)) |&gt; \n  kableExtra::pack_rows(index = table(tb_four_indiv$model))\n\n\n\n\nTable 3.2: Mappings from the marital_status categorical variable \\(x\\) to the compositional one \\(\\tilde{\\mathbf{x}}\\), for four individuals of the dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicted Scores\n\n\n\nmarital_status\nsex\nMarried\nNever-married\nSeparated\n\n\n\n\nGAM-MLR(1)\n\n\nNever-married\nMale\n0.3523\n0.2059\n0.4418\n\n\nMarried\nMale\n0.5428\n0.1054\n0.3519\n\n\nMarried\nFemale\n0.3026\n0.5988\n0.0986\n\n\nMarried\nFemale\n0.5957\n0.1710\n0.2333\n\n\nGAM-MLR(2)\n\n\nNever-married\nMale\n0.0052\n0.6323\n0.3625\n\n\nMarried\nMale\n1.0000\n0.0000\n0.0000\n\n\nMarried\nFemale\n1.0000\n0.0000\n0.0000\n\n\nMarried\nFemale\n1.0000\n0.0000\n0.0000\n\n\nRandom Forest\n\n\nNever-married\nMale\n0.0052\n0.7565\n0.2383\n\n\nMarried\nMale\n0.9944\n0.0000\n0.0056\n\n\nMarried\nFemale\n0.9652\n0.0348\n0.0000\n\n\nMarried\nFemale\n1.0000\n0.0000\n0.0000\n\n\nGradient Boosting Model\n\n\nNever-married\nMale\n0.0034\n0.6210\n0.3757\n\n\nMarried\nMale\n0.9991\n0.0003\n0.0007\n\n\nMarried\nFemale\n0.9980\n0.0018\n0.0001\n\n\nMarried\nFemale\n0.9992\n0.0005\n0.0003",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Adult Dataset</span>"
    ]
  },
  {
    "objectID": "application-adult.html#optimal-transport-in-the-euclidean-representation",
    "href": "application-adult.html#optimal-transport-in-the-euclidean-representation",
    "title": "3  Adult Dataset",
    "section": "3.3 Optimal Transport in the Euclidean Representation",
    "text": "3.3 Optimal Transport in the Euclidean Representation\nWe can now apply Algorithm 1.1 with a Gaussian mapping in an Euclidean representation space to transport from observed \\(\\widehat{\\mathbf{x}}_j|s=0\\) (scores for women) to counterfactual \\(\\widehat{\\mathbf{x}}_j|s=1\\) (scores for men), in \\(\\mathcal{S}_d\\).\n\n\n\n\n\n\nSubset\n\n\n\nWe will work on a subset of the data here for the transport. Also, if the number is too large, the returned weights tend to be all equal to 1…\n\n\n\nset.seed(1234)\nidx &lt;- sample(1:nrow(adult),size = 400)\nadult_subset &lt;- adult[idx, ]\n\nLet us isolate women and men:\n\nind_0 &lt;- which(adult_subset$sex == \"Female\")\nind_1 &lt;- which(adult_subset$sex == \"Male\")\n\nThen, we create matrices for each model with the predicted scores for each category, i.e., the representation of the categorical variable marital_status in the unit simplex.\n\n# GAM-MLR(1)\nX0_glm_1 &lt;- scores_glm_1[idx, ][ind_0, ]\nX1_glm_1 &lt;- scores_glm_1[idx, ][ind_1, ]\n# GAM-MLR(2)\nX0_glm_2 &lt;- scores_glm_2[idx, ][ind_0,]\nX1_glm_2 &lt;- scores_glm_2[idx, ][ind_1,]\n# RF\nX0_rf &lt;- scores_rf[idx, ][ind_0, ]\nX1_rf &lt;- scores_rf[idx, ][ind_1, ]\n# GBM\nX0_gbm &lt;- scores_gbm[idx, ][ind_0, ]\nX1_gbm &lt;- scores_gbm[idx, ][ind_1, ]\n\nFor the random forest and the gradient boosting model, we add a tiny bit to scores exactly equal to zero and substract the same tiny bit to scores exactly equal to one.\n\n# RF\nfor(i in 1:3) X0_rf[which(X0_rf[, i] == 0), i] = .0000001\nfor(i in 1:3) X0_rf[which(X0_rf[, i] == 1), i] = 1-.0000001\nfor(i in 1:3) X1_rf[which(X1_rf[, i] == 0), i] = .0000001\nfor(i in 1:3) X1_rf[which(X1_rf[, i] == 1), i] = 1-.0000001\n# GBM\nfor(i in 1:3) X0_gbm[which(X0_gbm[, i] == 0), i] = .0000001\nfor(i in 1:3) X0_gbm[which(X0_gbm[, i] == 1), i] = 1-.0000001\nfor(i in 1:3) X1_gbm[which(X1_gbm[, i] == 0), i] = .0000001\nfor(i in 1:3) X1_gbm[which(X1_gbm[, i] == 1), i] = 1-.0000001\n\nThen, we can apply Algorithm 1.1 to each set of predicted scores. We use the clr transform and Gaussian OT:\n\ntransp_glm_1 &lt;- transport_simplex(X0 = X0_glm_1, X1 = X1_glm_1, n_interp = 31)\ntransp_glm_2 &lt;- transport_simplex(X0 = X0_glm_2, X1 = X1_glm_2, n_interp = 31)\ntransp_rf &lt;- transport_simplex(X0 = X0_rf, X1 = X1_rf, n_interp = 31)\ntransp_gbm &lt;- transport_simplex(X0 = X0_rf, X1 = X1_gbm, n_interp = 31)\n\nWe can then have a look at the percentage of each purpose category in the initial dataset, compare it with the average predicted score of each category for each model, and with the average of the transported predicted score for women.\n\n\nCodes to create the Table.\n# Proportions of each purpose level by gender in the dataset\nprop_marital &lt;- \n  adult |&gt; \n  count(marital_status, sex) |&gt; \n  group_by(sex) |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  select(-n) |&gt; \n  pivot_wider(names_from = marital_status, values_from = prop) |&gt; \n  mutate(type = \"Categorical\")\n\nget_table_pred_transp &lt;- function(scores, transp_scores) {\n  # Average predicted scores for each purpose level by gender\n  mean_scores_by_gender &lt;- \n    adult_subset |&gt; \n    select(marital_status, sex) |&gt; \n    bind_cols(scores) |&gt; \n    group_by(sex) |&gt; \n    summarise(across(colnames(!!scores), ~mean(.x))) |&gt; \n    mutate(type = \"Composition\")\n  \n  # Average predicted transported score of women for each purpose level\n  mean_transp_scores_women &lt;- colMeans(transp_scores) |&gt; \n    as_tibble_row() |&gt;\n    mutate(type = \"Transported\", sex = \"Female -&gt; Male\")\n  \n  mean_scores_by_gender |&gt; \n    bind_rows(mean_transp_scores_women)\n}\n\ntb_pred_transp_mean &lt;-\n  prop_marital |&gt; mutate(model = \"obs\") |&gt; \n  bind_rows(\n    get_table_pred_transp(scores_glm_1[idx, ], transp_glm_1) |&gt; \n      mutate(model = \"glm_1\")\n  ) |&gt; \n  bind_rows(\n    get_table_pred_transp(scores_glm_2[idx, ], transp_glm_2) |&gt; mutate(model = \"glm_2\")\n  ) |&gt; \n  bind_rows(\n    get_table_pred_transp(scores_rf[idx, ], transp_rf) |&gt; mutate(model = \"rf\")\n  ) |&gt; \n  bind_rows(\n    get_table_pred_transp(scores_gbm[idx, ], transp_gbm) |&gt; mutate(model = \"gbm\")\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  ) |&gt; \n  relocate(model, .before = sex) |&gt; \n  relocate(type, .after = model)\n\ntb_pred_transp_mean |&gt; select(-model) |&gt; \n  kableExtra::kbl(\n  booktabs = TRUE, digits = 4,\n) |&gt; \n  kableExtra::kable_paper() |&gt; \n  kableExtra::add_header_above(c(\" \" = 2, \"Marital Status\" = 3)) |&gt; \n  kableExtra::pack_rows(index = table(tb_pred_transp_mean$model))\n\n\n\n\nTable 3.3\n\n\n\n\n\n\n\n\n\n\nMarital Status\n\n\n\n\n\ntype\n\n\nsex\n\n\nMarried\n\n\nNever-married\n\n\nSeparated\n\n\n\n\n\n\nObserved Values\n\n\n\n\nCategorical\n\n\nFemale\n\n\n0.1525\n\n\n0.4408\n\n\n0.4067\n\n\n\n\nCategorical\n\n\nMale\n\n\n0.6180\n\n\n0.2657\n\n\n0.1164\n\n\n\n\nGAM-MLR(1)\n\n\n\n\nComposition\n\n\nFemale\n\n\n0.3524\n\n\n0.3965\n\n\n0.2510\n\n\n\n\nComposition\n\n\nMale\n\n\n0.5040\n\n\n0.3104\n\n\n0.1856\n\n\n\n\nTransported\n\n\nFemale -&gt; Male\n\n\n0.4908\n\n\n0.3213\n\n\n0.1879\n\n\n\n\nGAM-MLR(2)\n\n\n\n\nComposition\n\n\nFemale\n\n\n0.1333\n\n\n0.4605\n\n\n0.4062\n\n\n\n\nComposition\n\n\nMale\n\n\n0.5959\n\n\n0.2732\n\n\n0.1309\n\n\n\n\nTransported\n\n\nFemale -&gt; Male\n\n\n0.7760\n\n\n0.0780\n\n\n0.1461\n\n\n\n\nRandom Forest\n\n\n\n\nComposition\n\n\nFemale\n\n\n0.1316\n\n\n0.4871\n\n\n0.3813\n\n\n\n\nComposition\n\n\nMale\n\n\n0.5929\n\n\n0.2769\n\n\n0.1302\n\n\n\n\nTransported\n\n\nFemale -&gt; Male\n\n\n0.4867\n\n\n0.3337\n\n\n0.1796\n\n\n\n\nGradient Boosting Model\n\n\n\n\nComposition\n\n\nFemale\n\n\n0.1353\n\n\n0.4604\n\n\n0.4043\n\n\n\n\nComposition\n\n\nMale\n\n\n0.5950\n\n\n0.2754\n\n\n0.1296\n\n\n\n\nTransported\n\n\nFemale -&gt; Male\n\n\n0.5165\n\n\n0.3137\n\n\n0.1698\n\n\n\n\nOptimal transport using the clr transformation, and Gaussian optimal transports, on the purpose scores in the German Credit database, with two logistic GAM models to predict scores, a random forest, and a boosting model. For observed values, the observed proportions of purpose categories are reported by gender. Then, for each model, the average of predicted scores by gender for each categories are shown (Composition). Lastly, the average of transported predicted scores for women are reported (Transported).\n\n\n\n\n\n\n3.3.1 Visualization of Transported Categories\nWe can then show the counterfactuals on a ternary plot, and graph the displacement interpolation when generationg from the factual (women) to the counterfactuals (men).\nFirst, we format the paths:\n\ntransp_glm_1_path &lt;- interpolated(transp_glm_1) |&gt; \n  list_rbind(names_to = \"id_obs\")\ntransp_glm_2_path &lt;- interpolated(transp_glm_2) |&gt; \n  list_rbind(names_to = \"id_obs\")\ntransp_rf_path &lt;- interpolated(transp_rf) |&gt; \n  list_rbind(names_to = \"id_obs\")\ntransp_gbm_path &lt;- interpolated(transp_gbm) |&gt; \n  list_rbind(names_to = \"id_obs\")\n\nThen, we can show, for each model, the representation in the simplex of the categorical variable marital_status, by gender (women in red and men in blue), as well as the displacement interpolation.\n\n\nCodes to create the Figure.\nscores_all &lt;- as_tibble(scores_glm_1[idx, ]) |&gt; \n  mutate(sex = adult_subset$sex, model = \"glm_1\") |&gt; \n  bind_rows(\n    as_tibble(scores_glm_2[idx, ]) |&gt; \n      mutate(sex = adult_subset$sex, model = \"glm_2\")\n  ) |&gt; \n  bind_rows(\n    as_tibble(as.data.frame(scores_rf[idx, ])) |&gt; \n      mutate(sex = adult_subset$sex, model = \"rf\")\n  ) |&gt; \n  bind_rows(\n    as_tibble(scores_gbm[idx, ]) |&gt; \n      mutate(sex = adult_subset$sex, model = \"gbm\")\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  )\n\ntransp_all_path &lt;- \n  transp_glm_1_path |&gt; \n  mutate(\n    sex = factor(\"Female\", levels = levels(adult_subset$sex)),\n    model = \"glm_1\"\n  ) |&gt; \n  bind_rows(\n    transp_glm_2_path |&gt; \n      mutate(\n        sex = factor(\"Female\", levels = levels(adult_subset$sex)),\n        model = \"glm_2\"\n      ) \n  ) |&gt; \n  bind_rows(\n    transp_rf_path |&gt; \n      mutate(\n        sex = factor(\"Female\", levels = levels(adult_subset$sex)),\n        model = \"rf\"\n      ) \n  ) |&gt; \n  bind_rows(\n    transp_gbm_path |&gt; \n      mutate(\n        sex = factor(\"Female\", levels = levels(adult_subset$sex)),\n        model = \"gbm\"\n      ) \n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  )\n\nggtern(\n  data = scores_all,\n  mapping = aes(x = Married, y = Separated, z = `Never-married`, colour = sex)\n) +\n  geom_point(size = .1) +\n  geom_line(\n    data = transp_all_path, \n    linewidth = .2, alpha = .8,\n    mapping = aes(group = id_obs)\n  ) +\n  scale_colour_manual(values = c(\"Female\" = \"red\", \"Male\" = \"blue\"), guide = \"none\") +\n  facet_wrap(~model) +\n  labs(x = \"Married\", y = \"Never-married\", z = \"Separated\") +\n  theme_paper() +\n  theme(\n    tern.axis.title = element_text(size = rel(.8))\n  )\n\n\n\n\n\nFigure 3.1: Optimal Transport using clr transform. Points in red are compositions for women, whereas points in blue are compositions for men. The lines indicate the displacement interpolation when generating counterfactuals.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Adult Dataset</span>"
    ]
  },
  {
    "objectID": "application-adult.html#optimal-transport-in-mathcals_3",
    "href": "application-adult.html#optimal-transport-in-mathcals_3",
    "title": "3  Adult Dataset",
    "section": "3.4 Optimal Transport in \\(\\mathcal{S}_3\\)",
    "text": "3.4 Optimal Transport in \\(\\mathcal{S}_3\\)\nLet us now use Algorithm 1.2 to create counterfactuals using matching in \\(\\mathcal{S}_3\\).\nTo that end, we use the wasserstein_simplex() function from our package.\n\n\n\n\n\n\nNote\n\n\n\nThe codes are a bit long to run. Here, we load results saved from a previously evaluated code.\n\n\n\nmapping_glm_1 &lt;- wasserstein_simplex(X0_glm_1, X1_glm_1)\nmapping_glm_2 &lt;- wasserstein_simplex(X0_glm_2, X1_glm_2)\nmapping_rf &lt;- wasserstein_simplex(X0_rf, X1_rf)\nmapping_gbm &lt;- wasserstein_simplex(X0_gbm, X1_gbm)\n\nif (!dir.exists(\"../output/\")) dir.create(\"../output/\", recursive = TRUE)\nsave(\n  mapping_glm_1, mapping_glm_2, mapping_rf, mapping_gbm,\n  file = \"../output/matching_adult.rda\"\n)\n\n\nload(\"../output/matching_adult.rda\")\n\nWe extract the estimated weights for all the individuals:\n\nM0_glm_1 &lt;- mapping_glm_1$plan * nrow(X0_glm_1)\nM0_glm_2 &lt;- mapping_glm_2$plan * nrow(X0_glm_2)\nM0_rf &lt;- mapping_rf$plan * nrow(X0_rf)\nM0_gbm &lt;- mapping_gbm$plan * nrow(X0_gbm)\n\nLet us focus on a single individual \\(x_{0,i}=\\):\n\ni &lt;- 3\n\nFor each model, we extract the representation of the marital_status characteristic in the simplex (i.e., the predicted scores by the \\(k\\)-th model, \\(\\widehat{m}^{(k)}(\\mathbf{x}_j|\\mathbf{x}_{-j})\\)). Let us denote this composition as \\(\\mathbf{x}_{0,i}^{(k)}\\)\n\nindiv_i_glm_1 &lt;- X0_glm_1[i, ]\nindiv_i_glm_2 &lt;- X0_glm_2[i, ]\nindiv_i_rf &lt;- X0_rf[i, ]\nindiv_i_gbm &lt;- X0_gbm[i, ]\n\nWe then extract the weights \\(\\mathbf{P}^{\\star(k)}_i\\):\n\nweights_i_glm_1 &lt;- M0_glm_1[i, ]\nweights_i_glm_2 &lt;- M0_glm_2[i, ]\nweights_i_rf &lt;- M0_rf[i, ]\nweights_i_gbm &lt;- M0_gbm[i, ]\n\nLastly, we compute, for our individual, its counterfactual \\(T^\\star(\\mathbf{x}_{0,i})\\), by simply computing the weighted average of the characteristics of the individuals from the other group.\n\ncfact_i_glm_1 &lt;- weights_i_glm_1 %*% X1_glm_1\ncfact_i_glm_2 &lt;- weights_i_glm_2 %*% X1_glm_2\ncfact_i_rf &lt;- weights_i_rf %*% X1_rf\ncfact_i_gbm &lt;- weights_i_gbm %*% X1_gbm\n\nWe can then plot (Figure 3.2) the representation of the woman of interest obtained for each model (red dot), and its counterfactual obtained by matching (blue dot). We also plot, on the ternary plot, all the women and men. The size of the dots for men is proportional to the weights corresponding to the women of interest.\n\n\nCodes to create the Figure.\n# Women\ntb_plot_females &lt;- \n  as_tibble(X0_glm_1) |&gt; \n  mutate(sex = \"Female\", model = \"glm_1\") |&gt; \n  bind_rows(\n    as_tibble(X0_glm_2) |&gt; \n      mutate(sex = \"Female\", model = \"glm_2\")\n  ) |&gt; \n  bind_rows(\n    as_tibble(X0_rf) |&gt; \n      mutate(sex = \"Female\", model = \"rf\")\n  ) |&gt; \n  bind_rows(\n    as_tibble(X0_gbm) |&gt; \n      mutate(sex = \"Female\", model = \"gbm\",)\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  )\n\n# Males individuals, with a column weights_i giving their weight used to \n# construct the counterfactual for indiv i\ntb_plot_males &lt;- \n  as_tibble(X1_glm_1) |&gt; \n  mutate(\n    sex = \"Male\", model = \"glm_1\", weights_i = weights_i_glm_1\n  ) |&gt; \n  bind_rows(\n    as_tibble(X1_glm_2) |&gt; \n      mutate(\n        sex = \"Male\", model = \"glm_2\", weights_i = weights_i_glm_2\n      )\n  ) |&gt; \n  bind_rows(\n    as_tibble(X1_rf) |&gt; \n      mutate(\n        sex = \"Male\", model = \"rf\", weights_i = weights_i_rf\n      )\n  ) |&gt; \n  bind_rows(\n    as_tibble(X1_gbm) |&gt; \n      mutate(\n        sex = \"Male\", model = \"gbm\", weights_i = weights_i_rf\n      )\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  )\n\nindiv_i &lt;- \n  as_tibble_row(indiv_i_glm_1) |&gt; mutate(sex = \"Female\", model = \"glm_1\") |&gt; \n  bind_rows(\n    as_tibble_row(indiv_i_glm_2) |&gt; mutate(sex = \"Female\", model = \"glm_2\")\n  ) |&gt; \n  bind_rows(\n    as_tibble_row(indiv_i_rf) |&gt; mutate(sex = \"Female\", model = \"rf\")\n  ) |&gt; \n  bind_rows(\n    as_tibble_row(indiv_i_gbm) |&gt; mutate(sex = \"Female\", model = \"gbm\")\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  )\n\ncfact_indiv_i &lt;- \n  as_tibble(cfact_i_glm_1) |&gt; mutate(sex = \"Male\", model = \"glm_1\") |&gt; \n  bind_rows(\n    as_tibble(cfact_i_glm_2) |&gt; mutate(sex = \"Male\", model = \"glm_2\")\n  ) |&gt; \n  bind_rows(\n    as_tibble(cfact_i_rf) |&gt; mutate(sex = \"Male\", model = \"rf\")\n  ) |&gt; \n  bind_rows(\n    as_tibble(cfact_i_gbm) |&gt; mutate(sex = \"Male\", model = \"gbm\")\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, \n      levels = c(\"obs\", \"glm_1\", \"glm_2\", \"rf\", \"gbm\"),\n      labels = c(\n        \"Observed Values\",\n        \"GAM-MLR(1)\", \"GAM-MLR(2)\", \"Random Forest\", \n        \"Gradient Boosting Model\"\n      )\n    )\n  )\n\nggtern(\n  mapping = aes(x = Married, y = Separated, z = `Never-married`, colour = sex)\n) +\n  geom_point(\n    data = tb_plot_females,\n    size = .1,\n    alpha = .6\n  ) +\n  geom_point(\n    data = tb_plot_males,\n    mapping = aes(size = weights_i),\n    alpha = .5\n  ) +\n  geom_point(data = indiv_i, size = 3, colour = \"white\") +\n  geom_point(data = indiv_i, size = 2) +\n  geom_point(data = cfact_indiv_i, size = 3, colour = \"white\", shape = 15) +\n  geom_point(data = cfact_indiv_i, size = 3, shape = 15) +\n  facet_wrap(~ model) +\n  labs(x = \"Married\", y = \"Separated\", z = \"Never Married\") +\n  scale_colour_manual(\n    values = c(\"Female\" = \"red\", \"Male\" = \"blue\"), guide = \"none\"\n  ) +\n  scale_size_continuous(range = c(0, 1), guide = \"none\") +\n  theme_paper() +\n  theme(\n    tern.axis.title = element_text(size = rel(.8))\n  )\n\n\n\n\n\nFigure 3.2: Empirical matching of a woman \\(\\mathbf{x}_{0,i}^{(k)}\\) (big red dot) with men (blue dots). The Size of blue dots are proportional to the weights \\(\\mathbf{P}^\\star_i\\). The counterfactual obtained with matching \\(T^\\star(\\mathbf{x}_{0,i})\\) is shown as a blue square.\n\n\n\n\n\n\n\n\nTo finish, let us look more closely to the i-th woman for which we have shown the counterfactual on the ternary plot. The value of the marital_status variable for her is Married:\n\nadult_subset[ind_0[i], \"marital_status\"]\n\n[1] Married\nLevels: Married Never-married Separated\n\n\nUsing the GAM-MLR(1) model, we obtained the following composition:\n\nX0_glm_1[i, ]\n\n      Married Never-married     Separated \n   0.14317730    0.81513857    0.04168414 \n\n\nThe closest points in the group of men, obtained using Algorithm 1.2 are:\n\nind_close_points &lt;- tail(order(weights_i_glm_1), 10)\nX1_glm_1[ind_close_points, ] |&gt; \n  as_tibble() |&gt; \n  mutate(\n    Purpose = adult_subset[ind_1[ind_close_points], ] |&gt; select(marital_status),\n    index = ind_close_points,\n    weights_i = weights_i_glm_1[ind_close_points]) |&gt; \n  arrange(desc(weights_i)) |&gt; \n  kableExtra::kbl(booktabs = TRUE) |&gt; \n  kableExtra::kable_paper()\n\n\n\n\nMarried\nNever-married\nSeparated\nPurpose\nindex\nweights_i\n\n\n\n\n0.2041504\n0.7544468\n0.0414028\nNever-married\n130\n0.4813495\n\n\n0.2381338\n0.7089583\n0.0529079\nNever-married\n89\n0.3645661\n\n\n0.1720608\n0.7923851\n0.0355542\nMarried\n119\n0.1544133\n\n\n0.0187499\n0.9619327\n0.0193173\nNever-married\n26\n0.0000035\n\n\n0.0050026\n0.9826104\n0.0123870\nNever-married\n200\n0.0000034\n\n\n0.7732104\n0.0600182\n0.1667714\nSeparated\n110\n0.0000034\n\n\n0.7790189\n0.0590491\n0.1619320\nMarried\n72\n0.0000034\n\n\n0.6202558\n0.1271203\n0.2526239\nMarried\n70\n0.0000033\n\n\n0.6417728\n0.1617917\n0.1964355\nSeparated\n257\n0.0000033\n\n\n0.5991270\n0.1735119\n0.2273610\nMarried\n44\n0.0000033\n\n\n\n\n\n\n\nThe counterfactual version for the composition is:\n\ncfact_i_glm_1\n\n       Married Never-married  Separated\n[1,] 0.2114987     0.7438497 0.04465168\n\n\nThe counterfactual categorical value would thus be:\n\ncolnames(cfact_i_glm_1)[which.max(cfact_i_glm_1)]\n\n[1] \"Never-married\"\n\n\nFor comparison, using Gaussian OT, the counterfactual would be:\n\ntransp_glm_1 |&gt; slice(i)\n\n# A tibble: 1 × 3\n  Married `Never-married` Separated\n    &lt;dbl&gt;           &lt;dbl&gt;     &lt;dbl&gt;\n1   0.250           0.709    0.0412",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Adult Dataset</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Brualdi, Richard A. 2006. Combinatorial Matrix Classes. Vol.\n13. Cambridge University Press.\n\n\nFernandes Machado, Agathe, Arthur Charpentier, and Ewen Gallic. 2025.\n“Sequential Conditional Transport on Probabilistic Graphs for\nInterpretable Counterfactual Fairness.” In Proceedings of the\nAAAI Conference on Artificial Intelligence. Vol. 39.\n\n\nHofmann, H. 1994. “German Credit Data.” UCI\nMachine Learning Repository. https://doi.org/10.24432/C5NC77.\n\n\nMcCann, Robert J. 1997. “A Convexity Principle for Interacting\nGases.” Advances in Mathematics 128 (1): 153–79.\n\n\nPal, Soumik, and Ting-Kam Leonard Wong. 2016. “The Geometry of\nRelative Arbitrage.” Mathematics and Financial Economics\n10: 263–93.\n\n\n———. 2020. “Multiplicative Schrödinger Problem and\nthe Dirichlet Transport.” Probability Theory and Related\nFields 178 (1): 613–54.\n\n\nPeyré, Gabriel, Marco Cuturi, et al. 2019. “Computational Optimal\nTransport: With Applications to Data Science.” Foundations\nand Trends in Machine Learning 11 (5-6): 355–607.\n\n\nPlečko, Drago, and Nicolai Meinshausen. 2020. “Fair Data\nAdaptation with Quantile Preservation.” Journal of Machine\nLearning Research 21 (242): 1–44.",
    "crumbs": [
      "References"
    ]
  }
]